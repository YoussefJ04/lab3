{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccef370",
   "metadata": {},
   "source": [
    "# ESIEE Paris — Data Engineering I — Assignment 3\n",
    "> Author : Badr TAJINI\n",
    "\n",
    "**Academic year:** 2025–2026  \n",
    "**Program:** Data & Applications - Engineering - (FD)   \n",
    "**Course:** Data Engineering I  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c7a52",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "- Analyze with **SQL** and **DataFrames**.\n",
    "- Implement two **RDD means** variants.\n",
    "- Implement **RDD joins** (shuffle and hash).\n",
    "- Record and explain performance observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f7c31",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e0ac51-c441-409d-8453-a1bc30bb55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:05:38) [MSC v.1929 64 bit (AMD64)]\n",
      "C:\\Users\\Youssef Jmal\\anaconda3\\envs\\spark312\\python.exe\n",
      "pyspark OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "import pyspark\n",
    "print(\"pyspark OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76cdb5-698f-4369-8c1f-2526d7785b45",
   "metadata": {},
   "source": [
    "Download data files from the following URL:\n",
    "https://www.dropbox.com/scl/fi/7012u693u06dgj95mgq2a/retail_dw_20250826.tar.gz?rlkey=fxyozuoryn951gzwmli5xi2zd&dl=0\n",
    "\n",
    "Unpack somewhere and define the `data_path` accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8073f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to path on your local machine.\n",
    "data_path = r\"D:\\DataEngineering\\lab3\\assignment\\data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93421e-3ed4-4adc-8dd9-f605b53c8498",
   "metadata": {},
   "source": [
    "The following cell contains setup to measure wall clock time and memory usage. (Don't worry about the details, just run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82905153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: scipy in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\youssef jmal\\anaconda3\\envs\\spark312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "psutil is installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy pandas pyarrow matplotlib scipy\n",
    "import sys, subprocess\n",
    "try:\n",
    "    import psutil  # noqa: F401\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"psutil\"])\n",
    "print(\"psutil is installed.\")\n",
    "\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import time, os, platform\n",
    "\n",
    "# Try to import optional modules\n",
    "try:\n",
    "    import psutil\n",
    "except Exception:\n",
    "    psutil = None\n",
    "\n",
    "try:\n",
    "    import resource  # not available on Windows\n",
    "except Exception:\n",
    "    resource = None\n",
    "\n",
    "\n",
    "def _rss_bytes():\n",
    "    \"\"\"Resident Set Size in bytes (cross-platform via psutil if available).\"\"\"\n",
    "    if psutil is not None:\n",
    "        return psutil.Process(os.getpid()).memory_info().rss\n",
    "    # Fallback: unknown RSS → 0 \n",
    "    return 0\n",
    "\n",
    "\n",
    "def _peak_bytes():\n",
    "    \"\"\"\n",
    "    Best-effort peak memory in bytes.\n",
    "    - Windows: psutil peak working set (peak_wset)\n",
    "    - Linux:   resource.ru_maxrss (KB → bytes)\n",
    "    - macOS:   resource.ru_maxrss (bytes)\n",
    "    Fallback to current RSS if unavailable.\n",
    "    \"\"\"\n",
    "    sysname = platform.system()\n",
    "\n",
    "    # Windows path: use psutil peak_wset if present\n",
    "    if sysname == \"Windows\" and psutil is not None:\n",
    "        mi = psutil.Process(os.getpid()).memory_info()\n",
    "        peak = getattr(mi, \"peak_wset\", None)  # should be available on Windows\n",
    "        if peak is not None:\n",
    "            return int(peak)\n",
    "        return int(mi.rss)\n",
    "\n",
    "    # POSIX path: resource may be available\n",
    "    if resource is not None:\n",
    "        try:\n",
    "            ru = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "            # On Linux ru_maxrss is in kilobytes; on macOS/BSD it is bytes\n",
    "            if sysname == \"Linux\":\n",
    "                return int(ru) * 1024\n",
    "            else:\n",
    "                return int(ru)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Last resort\n",
    "    return _rss_bytes()\n",
    "\n",
    "\n",
    "@register_cell_magic\n",
    "def timemem(line, cell):\n",
    "    \"\"\"\n",
    "    Measure wall time and memory around the execution of this cell.\n",
    "\n",
    "        %%timemem\n",
    "        <your code>\n",
    "\n",
    "    Notes:\n",
    "    - RSS = resident memory after the cell.\n",
    "    - Peak is OS-dependent (see _peak_bytes docstring).\n",
    "    \"\"\"\n",
    "    ip = get_ipython()\n",
    "\n",
    "    rss_before  = _rss_bytes()\n",
    "    peak_before = _peak_bytes()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Execute the cell body\n",
    "    result = ip.run_cell(cell)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rss_after  = _rss_bytes()\n",
    "    peak_after = _peak_bytes()\n",
    "\n",
    "    wall = t1 - t0\n",
    "    rss_delta_mb  = (rss_after  - rss_before)  / (1024 * 1024)\n",
    "    peak_delta_mb = (peak_after - peak_before) / (1024 * 1024)\n",
    "\n",
    "    print(\"======================================\")\n",
    "    print(f\"Wall time: {wall:.3f} s\")\n",
    "    print(f\"RSS Δ: {rss_delta_mb:+.2f} MB\")\n",
    "    print(f\"Peak memory Δ: {peak_delta_mb:+.2f} MB (OS-dependent)\")\n",
    "    print(\"======================================\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55796a4b-ef95-4351-b065-5bb435deda6f",
   "metadata": {},
   "source": [
    "The following code snippet should \"just work\" to initialize Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bc0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON = C:\\Users\\Youssef Jmal\\anaconda3\\envs\\spark312\\python.exe\n",
      "SPARK_HOME = C:\\Users\\Youssef Jmal\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\n",
      "spark-submit exists = True\n",
      "Spark: 4.0.1\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pyspark\n",
    "from pyspark.find_spark_home import _find_spark_home\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# --- Find Spark home and ensure spark-submit is reachable (Windows) ---\n",
    "spark_home = _find_spark_home()\n",
    "os.environ[\"SPARK_HOME\"] = spark_home\n",
    "\n",
    "spark_bin = os.path.join(spark_home, \"bin\")\n",
    "if spark_bin not in os.environ.get(\"PATH\", \"\"):\n",
    "    os.environ[\"PATH\"] = spark_bin + \";\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "# --- Ensure driver + workers use the SAME python executable (kernel python) ---\n",
    "py = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = py\n",
    "os.environ[\"PYSPARK_PYTHON\"] = py\n",
    "\n",
    "print(\"PYTHON =\", py)\n",
    "print(\"SPARK_HOME =\", os.environ[\"SPARK_HOME\"])\n",
    "print(\"spark-submit exists =\", os.path.exists(os.path.join(spark_bin, \"spark-submit.cmd\")))\n",
    "\n",
    "# Stop previous session if any\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# IMPORTANT:\n",
    "# Some Spark configs cannot be changed after SparkSession is created.\n",
    "# So stability-related options must be set here (before getOrCreate()).\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"A3\")\n",
    "    .master(\"local[*]\")\n",
    "\n",
    "    # memory / local stability\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\")\n",
    "\n",
    "    # shuffle / joins\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "\n",
    "    # Windows + local PySpark stability: avoid reusing python workers\n",
    "    .config(\"spark.python.worker.reuse\", \"false\")\n",
    "\n",
    "    # a bit more tolerance in local\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\")\n",
    "\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "sc = spark.sparkContext\n",
    "print(\"Spark:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7a530",
   "metadata": {},
   "source": [
    "## 2. Loading DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745a229-813a-463b-beee-7b7284b5ed21",
   "metadata": {},
   "source": [
    "Let's load the DataFrames and print out their schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31b3d2c-3dfc-4a63-ba32-f3f5dac21e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_key: integer (nullable = true)\n",
      " |-- user_key: integer (nullable = true)\n",
      " |-- age_key: integer (nullable = true)\n",
      " |-- product_key: integer (nullable = true)\n",
      " |-- brand_key: integer (nullable = true)\n",
      " |-- category_key: integer (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand_code: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_desc: string (nullable = true)\n",
      " |-- brand_key: integer (nullable = true)\n",
      " |-- category_key: integer (nullable = true)\n",
      " |-- product_key: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- brand_code: string (nullable = true)\n",
      " |-- brand_desc: string (nullable = true)\n",
      " |-- brand_key: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that you should have defined data_path above\n",
    "\n",
    "events_df   = spark.read.parquet(os.path.join(data_path, \"retail_dw_20250826_events\"))\n",
    "products_df = spark.read.parquet(os.path.join(data_path, \"retail_dw_20250826_products\"))\n",
    "brands_df   = spark.read.parquet(os.path.join(data_path, \"retail_dw_20250826_brands\"))\n",
    "\n",
    "events_df.printSchema()\n",
    "products_df.printSchema()\n",
    "brands_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9a33b-fc66-47da-8eb6-18554ff19bdf",
   "metadata": {},
   "source": [
    "How many rows are in each table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b70c3a3-4da7-41e9-9e64-ae8f870c29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in events   table: 42351862\n",
      "Number of rows in products table: 166794\n",
      "Number of rows in brands   table: 3444\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in events   table: {events_df.count()}\")\n",
    "print(f\"Number of rows in products table: {products_df.count()}\")\n",
    "print(f\"Number of rows in brands   table: {brands_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b16635-d1c3-4bf9-ba5a-49778d3f1530",
   "metadata": {},
   "source": [
    "We can register the DataFrames as tables and issue SQL queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc244b9-b5d5-42f9-8efe-f7c4ea095499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|42351862|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  166794|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    3444|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events_df.createOrReplaceTempView(\"events\")\n",
    "products_df.createOrReplaceTempView(\"products\")\n",
    "brands_df.createOrReplaceTempView(\"brands\")\n",
    "\n",
    "spark.sql('select count(*) from events').show()\n",
    "spark.sql('select count(*) from products').show()\n",
    "spark.sql('select count(*) from brands').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d7aad-277f-495f-965f-831c8d247e4a",
   "metadata": {},
   "source": [
    "As a sanity check, the corresponding values should match: counting the rows in the DataFrame vs. issuing an SQL query to count the number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a37092",
   "metadata": {},
   "source": [
    "## 3. Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93689a-e015-4007-9126-1e10e75d8dfa",
   "metadata": {},
   "source": [
    "Answer Q1 to Q7 below with SQL queries and DataFrame manipulations.\n",
    "\n",
    "**write some code here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf85258",
   "metadata": {},
   "source": [
    "### 3.1 Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393de9c-1479-480c-9948-881f368a19e3",
   "metadata": {},
   "source": [
    "For session_id `789d3699-028e-4367-b515-b82e2cb5225f`, what was the purchase price?\n",
    "\n",
    "**Hint:** We only care about purchase events.\n",
    "\n",
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794fe1d9-5eeb-4cbc-9fb2-5a44b0471da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|          session_id| price|\n",
      "+--------------------+------+\n",
      "|789d3699-028e-436...|100.39|\n",
      "+--------------------+------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.464 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb46c9220, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46c8260, raw_cell=\"# codecell_31a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_31a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_31a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    session_id,\n",
    "    price\n",
    "FROM events\n",
    "WHERE event_type = 'purchase'\n",
    "  AND session_id = '789d3699-028e-4367-b515-b82e2cb5225f'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "results = spark.sql(sql_query)\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b441e-741c-47bd-afea-26b6e259c4ad",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d74d4457-1f5d-4a90-8974-edc78417c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|          session_id| price|\n",
      "+--------------------+------+\n",
      "|789d3699-028e-436...|100.39|\n",
      "+--------------------+------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.562 s\n",
      "RSS Δ: +0.01 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb46c8ec0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46c89e0, raw_cell=\"# codecell_31b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_31b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_31b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "results_df = (\n",
    "    events_df\n",
    "    .filter(F.col(\"event_type\") == \"purchase\")\n",
    "    .filter(F.col(\"session_id\") == \"789d3699-028e-4367-b515-b82e2cb5225f\")\n",
    "    .select(\"session_id\", \"price\")\n",
    ")\n",
    "\n",
    "\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87aa67",
   "metadata": {},
   "source": [
    "### 3.2 Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4f80c-4d3e-4ed5-8a6a-065f7631739f",
   "metadata": {},
   "source": [
    "How many products are sold by the brand \"sokolov\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86f5c8-4dd2-4d9f-9216-ff3a34337fc8",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f8b9b4b-81de-4292-bbc8-34f66c3b2cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|nb_products_sold|\n",
      "+----------------+\n",
      "|             925|\n",
      "+----------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.964 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb45dd910, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb45de750, raw_cell=\"# codecell_32a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_32a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_32a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = \"\"\"\n",
    "SELECT COUNT(*) AS nb_products_sold\n",
    "FROM events e\n",
    "JOIN products p ON e.product_key = p.product_key\n",
    "JOIN brands b   ON p.brand_key = b.brand_key\n",
    "WHERE e.event_type = 'purchase'\n",
    "  AND lower(b.brand_code) = 'sokolov'\n",
    "\"\"\"\n",
    "results = spark.sql(sql_query)\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53249ee1-99aa-41e5-a484-c75342147fd8",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585b3df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|nb_products_sold|\n",
      "+----------------+\n",
      "|             925|\n",
      "+----------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.570 s\n",
      "RSS Δ: +0.03 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb45de1b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb45dfd70, raw_cell=\"# codecell_32b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_32b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_32b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "e = events_df.alias(\"e\")\n",
    "p = products_df.alias(\"p\")\n",
    "b = brands_df.alias(\"b\")\n",
    "\n",
    "results_df = (\n",
    "    e\n",
    "    .filter(F.col(\"e.event_type\") == \"purchase\")\n",
    "    .join(p, on=F.col(\"e.product_key\") == F.col(\"p.product_key\"), how=\"inner\")\n",
    "    .join(b, on=F.col(\"p.brand_key\") == F.col(\"b.brand_key\"), how=\"inner\")\n",
    "    .filter(F.lower(F.col(\"b.brand_code\")) == \"sokolov\")\n",
    "    .select(F.count(\"*\").alias(\"nb_products_sold\"))\n",
    ")\n",
    "\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc4800c",
   "metadata": {},
   "source": [
    "### 3.3 Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e553ce-aa6d-416e-a0f3-6d5b5fe160a0",
   "metadata": {},
   "source": [
    "What is the average purchase price of items purchased from the brand \"febest\"? (Report answer to two digits after the decimal point, i.e., XX.XX.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d59f4-9d27-4b03-9935-aa3aaa797a8d",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19187c9f-06ce-4364-bf7b-998797ca6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg_purchase_price|\n",
      "+------------------+\n",
      "|             20.39|\n",
      "+------------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.782 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb45df860, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb45dec90, raw_cell=\"# codecell_33a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_33a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_33a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = \"\"\"\n",
    "SELECT ROUND(AVG(e.price), 2) AS avg_purchase_price\n",
    "FROM events e\n",
    "JOIN products p ON e.product_key = p.product_key\n",
    "JOIN brands  b ON p.brand_key = b.brand_key\n",
    "WHERE e.event_type = 'purchase'\n",
    "  AND e.price IS NOT NULL\n",
    "  AND LOWER(b.brand_desc) LIKE '%febest%'\n",
    "\"\"\"\n",
    "results = spark.sql(sql_query)\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d1667-6646-4e1b-be7a-c18228861857",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eade2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg_purchase_price|\n",
      "+------------------+\n",
      "|             20.39|\n",
      "+------------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.669 s\n",
      "RSS Δ: +0.01 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb45de7b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb45dfa10, raw_cell=\"from pyspark.sql import functions as F\n",
       "\n",
       "e = events..\" transformed_cell=\"from pyspark.sql import functions as F\n",
       "\n",
       "e = events..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "e = events_df.alias(\"e\")\n",
    "p = products_df.alias(\"p\")\n",
    "b = brands_df.alias(\"b\")\n",
    "\n",
    "base = (\n",
    "    e.filter(F.col(\"e.event_type\") == \"purchase\")\n",
    "     .filter(F.col(\"e.price\").isNotNull())\n",
    "     .join(p, F.col(\"e.product_key\") == F.col(\"p.product_key\"), \"inner\")\n",
    "     .join(b, F.col(\"p.brand_key\") == F.col(\"b.brand_key\"), \"inner\")\n",
    ")\n",
    "\n",
    "results_df = (\n",
    "    base\n",
    "    .filter(F.lower(F.col(\"b.brand_desc\")).contains(\"febest\"))   # <- IMPORTANT\n",
    "    .select(F.round(F.avg(\"e.price\"), 2).alias(\"avg_purchase_price\"))\n",
    ")\n",
    "\n",
    "results_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394c731",
   "metadata": {},
   "source": [
    "### 3.4 Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66317c46-94f7-459d-a99b-5e1bba29c6cf",
   "metadata": {},
   "source": [
    "What is the average number of events per user? (Report answer to two digits after the decimal point, i.e., XX.XX.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0888b2-4961-458f-8f58-c9bf29a360dc",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dab447c-b909-4155-a925-d1b01e3420e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg_events_per_user|\n",
      "+-------------------+\n",
      "|              14.02|\n",
      "+-------------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.304 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb46ca1b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46cb4a0, raw_cell=\"# codecell_34a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_34a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_34a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = \"\"\"\n",
    "SELECT ROUND(AVG(nb_events), 2) AS avg_events_per_user\n",
    "FROM (\n",
    "    SELECT user_key, COUNT(*) AS nb_events\n",
    "    FROM events\n",
    "    GROUP BY user_key\n",
    ") t\n",
    "\"\"\"\n",
    "results = spark.sql(sql_query)\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea6bc1-5ee3-4951-8c3c-0c326ebb3b2b",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9c5696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg_events_per_user|\n",
      "+-------------------+\n",
      "|              14.02|\n",
      "+-------------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.395 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb46f7920, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46f78f0, raw_cell=\"# codecell_34b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_34b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_34b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "results_df = (\n",
    "    events_df\n",
    "    .groupBy(\"user_key\")\n",
    "    .agg(F.count(\"*\").alias(\"nb_events\"))\n",
    "    .agg(F.round(F.avg(\"nb_events\"), 2).alias(\"avg_events_per_user\"))\n",
    ")\n",
    "\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd30e9",
   "metadata": {},
   "source": [
    "### 3.5 Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e011a70-e6e3-46fc-8ff7-041a919dca2b",
   "metadata": {},
   "source": [
    "What are the top 10 (`product_name`, `brand_code`) pairs in terms of revenue? We want the answer rows sorted by revenue in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ca411-eef0-45cf-bd92-99ece1d89510",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d4e788-9576-4122-9d5a-8c1532feef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|product_name|brand_code|       revenue|\n",
      "+------------+----------+--------------+\n",
      "|  smartphone|     apple|1.6711340803E8|\n",
      "|  smartphone|   samsung| 9.546627508E7|\n",
      "|  smartphone|    xiaomi| 2.254972634E7|\n",
      "|        NULL|      NULL| 1.673241267E7|\n",
      "|  smartphone|    huawei| 1.363398709E7|\n",
      "|    video.tv|   samsung| 1.220999247E7|\n",
      "|  smartphone|      NULL| 1.199712625E7|\n",
      "|        NULL|   lucente|    9556989.32|\n",
      "|    notebook|      acer|    8963128.65|\n",
      "|      clocks|     apple|    8622900.64|\n",
      "+------------+----------+--------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 3.879 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb472c2c0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb472c260, raw_cell=\"# codecell_35a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_35a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_35a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    p.product_name,\n",
    "    p.brand_code,\n",
    "    ROUND(SUM(e.price), 2) AS revenue\n",
    "FROM events e\n",
    "JOIN products p\n",
    "    ON e.product_key = p.product_key\n",
    "WHERE e.event_type = 'purchase'\n",
    "GROUP BY p.product_name, p.brand_code\n",
    "ORDER BY revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "results = spark.sql(sql_query)\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfe9ba-cd8b-4482-9d9d-c5d0501940bf",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1267c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------+\n",
      "|product_name|brand_code|revenue       |\n",
      "+------------+----------+--------------+\n",
      "|smartphone  |apple     |1.6711340803E8|\n",
      "|smartphone  |samsung   |9.546627508E7 |\n",
      "|smartphone  |xiaomi    |2.254972634E7 |\n",
      "|NULL        |NULL      |1.673241267E7 |\n",
      "|smartphone  |huawei    |1.363398709E7 |\n",
      "|video.tv    |samsung   |1.220999247E7 |\n",
      "|smartphone  |NULL      |1.199712625E7 |\n",
      "|NULL        |lucente   |9556989.32    |\n",
      "|notebook    |acer      |8963128.65    |\n",
      "|clocks      |apple     |8622900.64    |\n",
      "+------------+----------+--------------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.786 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb472a960, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb472a870, raw_cell=\"# codecell_35b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_35b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_35b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "results_df = (\n",
    "    events_df\n",
    "    .filter(F.col(\"event_type\") == \"purchase\")\n",
    "    .join(products_df, on=\"product_key\", how=\"inner\")\n",
    "    .groupBy(\"product_name\", \"brand_code\")\n",
    "    .agg(F.round(F.sum(\"price\"), 2).alias(\"revenue\"))\n",
    "    .orderBy(F.col(\"revenue\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "results_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab771d9",
   "metadata": {},
   "source": [
    "### 3.6 Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fcb44-d4a3-4e6e-8dc9-25cc1186b641",
   "metadata": {},
   "source": [
    "Tally up counts of events by hour.\n",
    "More precisely, we want a table with hours 0, 1, ... 23 with the counts of events in that hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a15e7a-fed4-4229-86a4-5e57d0390581",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8436405-44fc-4852-9f7a-ad13e26623dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|hour|  count|\n",
      "+----+-------+\n",
      "|   0| 263808|\n",
      "|   1| 223635|\n",
      "|   2| 353509|\n",
      "|   3| 623434|\n",
      "|   4|1137209|\n",
      "|   5|1605037|\n",
      "|   6|1955461|\n",
      "|   7|2131930|\n",
      "|   8|2269469|\n",
      "|   9|2332649|\n",
      "|  10|2380185|\n",
      "|  11|2335494|\n",
      "|  12|2282992|\n",
      "|  13|2181477|\n",
      "|  14|2171196|\n",
      "|  15|2407266|\n",
      "|  16|2717710|\n",
      "|  17|2988054|\n",
      "|  18|3008559|\n",
      "|  19|2631424|\n",
      "|  20|1999466|\n",
      "|  21|1244129|\n",
      "|  22| 694728|\n",
      "|  23| 413041|\n",
      "+----+-------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.251 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb46c9e20, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46caf00, raw_cell=\"# codecell_36a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_36a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_36a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = f\"\"\"\n",
    "\n",
    "SELECT\n",
    "  hour(event_time) AS hour,\n",
    "  COUNT(*) AS count\n",
    "FROM events\n",
    "GROUP BY hour(event_time)\n",
    "ORDER BY hour\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "results = spark.sql(sql_query)\n",
    "\n",
    "results.show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5385c-10b5-4768-a88d-d0733ec0d64e",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36fc5060-a437-48f5-aa50-8602e9f1ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|hour|  count|\n",
      "+----+-------+\n",
      "|   0| 263808|\n",
      "|   1| 223635|\n",
      "|   2| 353509|\n",
      "|   3| 623434|\n",
      "|   4|1137209|\n",
      "|   5|1605037|\n",
      "|   6|1955461|\n",
      "|   7|2131930|\n",
      "|   8|2269469|\n",
      "|   9|2332649|\n",
      "|  10|2380185|\n",
      "|  11|2335494|\n",
      "|  12|2282992|\n",
      "|  13|2181477|\n",
      "|  14|2171196|\n",
      "|  15|2407266|\n",
      "|  16|2717710|\n",
      "|  17|2988054|\n",
      "|  18|3008559|\n",
      "|  19|2631424|\n",
      "|  20|1999466|\n",
      "|  21|1244129|\n",
      "|  22| 694728|\n",
      "|  23| 413041|\n",
      "+----+-------+\n",
      "\n",
      "======================================\n",
      "Wall time: 1.902 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfab91eb40, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb46ca6f0, raw_cell=\"# codecell_36b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_36b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_36b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "events_by_hour_df = (\n",
    "    events_df\n",
    "    .withColumn(\"hour\", F.hour(\"event_time\"))\n",
    "    .groupBy(\"hour\")\n",
    "    .count()\n",
    "    .orderBy(\"hour\")\n",
    ")\n",
    "\n",
    "events_by_hour_df.show(24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b294736-e759-4942-939d-5f8545f1ea89",
   "metadata": {},
   "source": [
    "When you run the cell above, `events_by_hour_df` should be something like:\n",
    "\n",
    "```\n",
    "+----+-------+\n",
    "|hour|  count|\n",
    "+----+-------+\n",
    "|   0|    ???|\n",
    "|   1|    ???|\n",
    "  ...\n",
    "|  23|    ???|\n",
    "+----+-------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42738a71-361d-4508-89ef-a5c255f1d505",
   "metadata": {},
   "source": [
    "Now plot the above DataFrame using `matplotlib`.\n",
    "Here we want a line graph, with hour on the _x_ axis and count on the _y_ axis.\n",
    "\n",
    "**Hint:** use the code below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1bcafdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 2.869 s\n",
      "RSS Δ: +25.66 MB\n",
      "Peak memory Δ: +23.91 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb45dd8e0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb45df290, raw_cell=\"# codecell_36c (keep this id for tracking purposes..\" transformed_cell=\"# codecell_36c (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_36c (keep this id for tracking purposes)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "events_by_hour_pdf = events_by_hour_df.toPandas()\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(events_by_hour_pdf[\"hour\"], events_by_hour_pdf[\"count\"])\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.title(\"Events per hour\")\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10445d63",
   "metadata": {},
   "source": [
    "### 3.7 Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498671fc-16a7-4da2-b9ea-2a18a0564d03",
   "metadata": {},
   "source": [
    "We are going to analyze the \"big\" brands. Find out the average purchase price by brand, and restrict to cases where the average is more than 10K.\n",
    "We want the results sorted by the average purchase price from the largest to smallest value.\n",
    "(Report answers to two digits after the decimal point, i.e., XX.XX, but it's okay if the output only contains one digit after the decimal point.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba375938-7e73-4512-8939-b289c78a89d3",
   "metadata": {},
   "source": [
    "First, do it using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec28857-1a72-4541-8260-d28bcfb28dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|brand_code|avg_price|\n",
      "+----------+---------+\n",
      "|      adam|  58946.0|\n",
      "|      kona|  43759.0|\n",
      "|  yuandong|  35329.0|\n",
      "|   bentley|  23164.0|\n",
      "|      otex| 18633.14|\n",
      "|    suunto| 10732.82|\n",
      "|     stark| 10400.25|\n",
      "+----------+---------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.896 s\n",
      "RSS Δ: +0.00 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb59bcad0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb59be360, raw_cell=\"# codecell_37a (keep this id for tracking purposes..\" transformed_cell=\"# codecell_37a (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_37a (keep this id for tracking purposes)\n",
    "\n",
    "# Write your SQL below\n",
    "sql_query = f\"\"\"\n",
    "\n",
    "SELECT\n",
    "  b.brand_code AS brand_code,\n",
    "  ROUND(AVG(e.price), 2) AS avg_price\n",
    "FROM events e\n",
    "JOIN brands b\n",
    "  ON e.brand_key = b.brand_key\n",
    "WHERE e.event_type = 'purchase'\n",
    "GROUP BY b.brand_code\n",
    "HAVING AVG(e.price) > 10000\n",
    "ORDER BY avg_price DESC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "results = spark.sql(sql_query)\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9495a-d3f5-4ae8-9698-3e24499d2696",
   "metadata": {},
   "source": [
    "Next, do it with DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66223d77-75b5-4168-b656-149c32561e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|brand_code|avg_price|\n",
      "+----------+---------+\n",
      "|      adam|  58946.0|\n",
      "|      kona|  43759.0|\n",
      "|  yuandong|  35329.0|\n",
      "|   bentley|  23164.0|\n",
      "|      otex| 18633.14|\n",
      "|    suunto| 10732.82|\n",
      "|     stark| 10400.25|\n",
      "+----------+---------+\n",
      "\n",
      "======================================\n",
      "Wall time: 2.617 s\n",
      "RSS Δ: +0.03 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb5939970, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb5938860, raw_cell=\"# codecell_37b (keep this id for tracking purposes..\" transformed_cell=\"# codecell_37b (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_37b (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "avg_price_by_brand_df = (\n",
    "    events_df\n",
    "    .filter(F.col(\"event_type\") == \"purchase\")\n",
    "    .join(brands_df.select(\"brand_key\", \"brand_code\"), on=\"brand_key\", how=\"inner\")\n",
    "    .groupBy(\"brand_code\")\n",
    "    .agg(F.round(F.avg(\"price\"), 2).alias(\"avg_price\"))\n",
    "    .filter(F.col(\"avg_price\") > 10000)\n",
    "    .orderBy(F.col(\"avg_price\").desc())\n",
    ")\n",
    "\n",
    "avg_price_by_brand_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9ef73-ac15-4895-a932-09a48f6b3e2d",
   "metadata": {},
   "source": [
    "When you run the cell above, `avg_price_by_brand_df` should be something like:\n",
    "\n",
    "```\n",
    "+----------+------------------+\n",
    "|brand_code|         avg_price|\n",
    "+----------+------------------+\n",
    "|       ???|               ???|\n",
    "        ...\n",
    "|       ???|               ???|\n",
    "+----------+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2546c5d-7c52-4910-8af6-bd6373e6b6c8",
   "metadata": {},
   "source": [
    "Now plot the above DataFrame using `matplotlib`.\n",
    "Here we want a bar chart, with each of the brands as a bar, and the average price on the _y_ axis.\n",
    "\n",
    "**Hint:** use the code below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0887f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAablJREFUeJzt3Qm8TPUf//GPfd/3NQpFdrJUiEQhiQolKm1C2ZeSrUIoFFFU2smvUvZEZV+ylD1CyJ5ddvN/vL///5n/3Ovi3uuOe2fu6/l4jGvOOXPmzPnOOXM+5/v9fr5JfD6fzwAAAAAAQJxLGverBAAAAAAABN0AAAAAAAQRNd0AAAAAAAQJQTcAAAAAAEFC0A0AAAAAQJAQdAMAAAAAECQE3QAAAAAABAlBNwAAAAAAQULQDQAAAABAkBB0AwDC2vjx4y1JkiT222+/WWKjz923b9/r+p6FChWyBg0aBPU9fvnlF/fZ/ve//1ko8LZXf6Nj8ODBdsstt9jFixeDvm2Ie2PGjLGCBQvamTNn2L0AHIJuAIiF9957z11EV65cmf0HIM4cO3bM3nzzTevevbslTZo4LtMmTpxoLVq0sKJFi7rz6l133XXZZRXIat/kzZvX0qRJ487Bs2fPjnLZRYsW2Z133mlp06a13Llz24svvmgnTpwI+jqfeOIJO3v2rL3//vsx3hcAwlPiOJsDQBz74osvXI3esmXLbMuWLexfJEinTp2yXr16xfdmIAY++ugjO3/+vDVv3jzR7LfRo0fb999/bwUKFLAsWbJccVkFtG+//bY99thjNmLECEuWLJnVq1fPFixYEGG51atX2913323//fefW/7pp5+2Dz74wB5++OGgrzN16tTWqlUrt4zP57umfQMgTPgAADGydetWXUX5vv32W1+OHDl8ffv2ve578MKFC75Tp075EquYfP6PP/7Yldfy5ct9iUF8fzduuOEGX/369YP6Hj///LMr00mTJsXq9SdPnvRdT9726u/VlC5d2teiRQtfQnbixAnfX3/9FWfr27Fjh/veyq233uqrUaNGlMstXbrU7cchQ4b4p+m7ftNNN/mqVq0aYdn77rvPlydPHt/Ro0f908aOHeteP2vWrKCuU3777Tc3fc6cObHYIwDCDTXdABCLWm7VxtSvX98eeugh99xz7tw5y5o1qz355JNRNhtVDUiXLl0iNGvs06ePFSlSxFKlSuVqerp163ZJX0A1uWzXrp17r1tvvdUtO3PmTDdv6NChdvvtt1u2bNlc08gKFSpE2ddVtZ5qCpk9e3bLkCGDNWzY0P75558o+/1q+lNPPWW5cuVy76X3VA1cdARu68033+w+s7Zp3rx5l9QuqbVAZNoWrSO6n1/b2rp1a9c0VNMLFy5sbdq0cc07A2mfdurUyXLkyGHp0qWzBx980A4cOBBhGdW2qVy9dd1000322muv2YULFyIst3nzZmvSpIlrXqrPlz9/fmvWrJkdPXo0wnKff/65++wqF30vtMzOnTuvug+9fbBx40Z75JFHLGPGjK58X3rpJTt9+nS0983lyvZq++vIkSPWoUMH933UMvp+qslzTPoY//jjj1a2bFm3f0qUKGHffvutf97WrVvdtg0bNizK5rua99VXX131PVQuL7/8sisHlam+05H3r5oqlyxZ0lasWGHVq1d3zYL1mpiUt7eO9evXW82aNd068uXL5/peR7Zr1y5r1KiR256cOXNax44do923d9u2bfbHH39Y7dq1L5kXneNc26jti0zlpu3V+crz77//2uOPP+6+W5kzZ3Y1s7///rvb98qDcCU6bvSdqFWrln355ZeXfCdjSt+z6DSl1+dVLfSzzz7rn6bvl77Pixcv9pe9zrVqHq4m6/p8npYtW1r69Ont66+/Duo6ReWjY17fMQBIzi4AgJhRcNO4cWNLmTKlawKqppHLly+32267zVKkSOGCOQUY6s+nZTyTJ092F98KvLwLYQUJasKoC77ixYvbmjVrXCDy559/uuUDzZ07113YKcBS4OwFrGoOqfWoaaQCpwkTJrjmjlOnTnUBRWCQq9frQrtKlSr266+/Rpjv2bdvn5vvBXMKUmfMmOEuQnXhqWDsarRu9dNUkK9gRn3g7733XtccX4FBbET1+Xfv3m2VKlVyQaL2oZJPKajUhbSagAbu//bt27ubJbrJsX37dhs+fLhbl7bTo2BDF9AKzvVX79m7d2/3uYcMGeKW0T6uW7euK0utUwGf3lP7W9uRKVMmt9wbb7xhr776qgua1QxVgcq7777rAr9Vq1a5QOdq9Fp9zoEDB9qSJUvsnXfescOHD9unn3561X0TlejsL/2tUaOGm/7cc8+5hFAKhHv27Gl79uxx++1qdFOiadOm9vzzz7tg7uOPP3bfSd0MuOeee+zGG2+0O+64wx1LCkoDaZpuCj3wwANXfR/tY31P1R93//79btsUsKoZsALTwADzvvvuc8eegibdTIpueXu03/Ud1rGvctE+0/uWKlXKrdu7saXmxzt27HDffQXzn332mVtvdGg/S/ny5S+ZF53jXPtcN1n27t3rvpcenWNU9oHnnvvvv98dj7rhou+BgkOVVXTkyZPH3QRQuWp79F3WX50jypUrZ8Gi46ZYsWIRgl7Rd1pU7grgdR5VE/2KFStGWE7fb90I0nqCuU6PynHhwoVx8MkBhLz4rmoHgFDiNRmcPXu2e37x4kVf/vz5fS+99JJ/GTUz1DJTpkyJ8Np69er5brzxRv/zzz77zJc0aVLf/PnzIyw3ZswY9/qFCxf6p+m5ll23bt0l2/Tff/9FeH727FlfyZIlfbVq1fJPW7FihVtHhw4dIiz7xBNPuOl9+vTxT2vdurVrQnnw4MEIyzZr1syXKVOmS94vMq1PD+0rz99//+1LnTq178EHH/RPa9WqlWuKHJm2JfLP0+U+f8uWLd30qJqOq2wCm5fXrl3bP006duzoS5Ysme/IkSP+aVF9tueee86XNm1a3+nTp93zVatWXbVp8/bt292633jjjQjT16xZ40uePPkl0y+3Dxo2bBhh+gsvvOCm//7771fdN968wLKNzv567bXXfOnSpfP9+eefEeb36NHDfSY1Bb4Slane95tvvvFPU3NcfafKlSvnn/b++++75TZs2BDhu5s9e3b33YhOc+18+fL5jh075p/+9ddfu+kjRozwT1NTZU3TcRVZdMo7cB2ffvqpf9qZM2d8uXPn9jVp0sQ/bfjw4W45bUdgU/YiRYpEq3l5r1693HLHjx+P1XG+adMm9/p33333ku9N+vTp/etQ2Wg5ba9Hzbu1Lk3XMRNdy5Yt8z3//PO+zJkzu9eqjEeNGuU7fPiwLzau1Lxc8wI/r0ff/cAy1rGp5/Pmzbtk2YcfftiVWzDX6Xn22Wd9adKkuepnBhD+aF4OADGgWjjVknlNOFXLptol1Tp5TVLV5FK1jYE1qKolU9NELeuZNGmSq91WLdPBgwf9D71efv755wjvrdpHNdONLLBGT++jJs7VqlWzlStX+qd7zY1feOGFCK9VTW2kG7H2zTffuFow/T9wu1S7q3UHrvdyqlat6ppXelRbqprLWbNmXdJ0N7oif37V1qk1gLY1cu2TRG6irprdwGnaR9qWv//+O8p9efz4cfe5tZxqf9XUW7yabH0WTY+KWjpo+1QjGrgPVfuoDM2Ry/Zy2rZtG2V5TZ8+/Yr7JirR3V/6Xuozq1VA4LarBln7K3I3gaiohlctPjyqRVQzXNUGqhZWtG/UjDewe4b2qd5LtdHRoXWqVtyj5tOqhY28f9TaIqouH9Epb49qwgO3SzWcqg1VU3mP3lfvH9iMW03RA5suX4lq5JMnT+7eKzbHuWpsVesaeO5RmalWXuXurUPnA7XKeeaZZ/zLqXl35O9bdKiFj1r7qBWEylJNqtXiQvtB+0u1/nFFLQlUlpHpe+TND/x7uWW9+cFap0fHkKZf7jwBIPEg6AaAaNLFq4JrBdzqe6ms5XpoeBk1yZ4zZ45bThfN6u+r5ppeX04FYervHRh0qwnuunXrXPPtwIcunEXNZQOp721U1LxUzcF14acLXq1DF8GB/YsVWOqiOvI61C8zkJpAq+mxMvJG3i4vaIm8XVFRYBmZPpcuPiP3o46uyNuu9agZcHSbqyvwD+RlSVYA41F5KFhUYK1AUZ/bC7S8/antUHPkcePGuZsruhkxatSoCPtbZaubFtoPkffjhg0borUPo9qP6nOsclTz+Cvtm6hEd39p2xWURd5ur59xdLZd36vINz2877W37WqSrEBQfYI9CtrU99i78RTT/aP31HtH3j9aZ2BXg5iUt0f99iN/Jn2HAr8/Os6i+uzKbXCtonOci84xatKs7gGiscFVZoHnHm2ngmLdELjS+SAmtF2PPvqo++6oKbxu8qg8o3OTLrp00yCq/vFen3LvpoL393LLBt7ACMY6PV7m8sjfBwCJD326ASCa1C9TtTkKvPWITBeYderUcf9X30n16VZfaCVVUn9b1WiXKVPGv7wuStUfVMPKREX9CANFdVE3f/58189T/YTVb1oX0qrBUl/LwGAmurxEWQo8Lte/s3Tp0hYXLncherma8Kg+f0woWVJUvAtj3WxQjbGCr/79+7sAV4GEggb13Q1MIvbWW2+5PvK6saKEYeq/6/W7VnCmZfX5VP5RvW9UNZnXss+udd8E0rar37US+kXFC57jgmqqVbOuvsw6Fn744QfXGiOux6eOav/EpLyj8/2JC0qSpn7DqnUPrMGPyXGu4Fr977VflX9B5x7dVFB/9GDSzSRtj/qwqzWDkvqpj3dUid1iS5/bu5kQSOdlr4WFt1zg9MjLessFa50e3ZDRjY24PD4BhCaCbgCIJgXVykasWs3IVJP93Xff2ZgxY9wFli6OdZGmZp533nmnC9hfeeWVCK/RRb6yBSvxUmxrQtQUXIGCmuUGNnvUxW+gG264wQURqqEPrB2MPMa4as90sa/AN6oMytGl2tLIlBxOF6B6D6+WUIFPZIHNva9E61HAtHbtWosLqhFU816VpcrPo30WFQWJemgcbAWNSgym8n/99ddd2SoYUw30tQSp2o+BtdgqL5Xj5RKlxcX+0rafOHHimspf26nPH/i9VvlL4LYrENR26dhSixG1hFCiv9h+z/Seeu/o3BiKaXlHh44z7d/In33Tpk3Rer1uzHnbEPgZonuci74vavauc4+aeevz6cZf4Ou0nerioP0dWNsd+XxwNapl1/toZIOlS5e6m0kK+pU4ULXycU1N57XdarERmPhM7+3NF7XmUIuj3377zXVj8CgBnRKjBU4Lxjo9Kkd1IQIAmpcDQDSoX54uXhs0aOD6a0Z+6OJWtVOqqRPV1Gn6lClTXM2Paq8Cm3eKLtJUwzJ27Ngo3+/kyZNX3S7VvuniPrB2WE1rI2c+VxNoUS1ZIGXTjrw+NY3XRX5UwVl0m4ZrqJ3AZqUadke1wmoJ4NUYKrjTRbuGSAqsMdLNi+jQPlYwoX2sC+FrrYH0tivwdbqgjrzPdHGu8gyk4Fvb4zU9VYZrra9fv36XbIeeK9iLjsg3eLzy8rJlx0R095e+lyo/BXiR6SZJ5M8eFWXKDixH7TNlXFcAE5hVW0GMRgBQbawyiWs/xqQlhdap486jvsv6DkVn/0S3vGOiXr167rMHDuWlwFbdNaJDuRAkcvlE9zj36FyjVhcKhtVPPfK5R+cDdXcJPPfoZk5UNxSjon2u1jC6sagM99o2dbfQvtffYATconOq9kHg/tQxp5sPumnjtQ5Szb5uGmnIvsDvh87FuqGkrO/BXKdH50AN8wYAZC8HgGiYMGGCy1w7efLkKOcr82+OHDl8999/v3/aggUL3GsyZMjgK1WqVJSvUUbzJEmSuMzgyjisbMLKBJw1a9YIGaa1nrZt216yjjlz5rh51apV840ePdrXr18/X86cOX2lS5e+JAO4sixr2uOPP+6yCz/yyCO+smXLuml9+/b1L7d3716XgVoZnJWVXVmmBw4c6DL0ZsmS5ar7SutTVmVloe7fv7/vzTffdOtT9vLArNvKjq4s2crors89YMAAX4ECBXzly5ePMnt5VJ9/165dLmuwtlWZ2bWt+izKSOxlT/ayl0fO2O1lwPYySmt79Pm0rW+99Zbv7bffdpmYy5QpE2G57777zmXN1vu99957vnfeecd32223+VKkSOFbvHixf/3aZ3rd7bff7hs8eLArn27duvmKFi3qGzJkSLSyl+t7o++UyqtFixZu2qOPPhqtfRNV9vLo7C9l21YZKMv6008/7bZ76NChLqO4yuvAgQNX3Hbtv2LFirls1sp4PmzYMPc5lDV95syZlx0RQA99V6LDKzutV991vYfeS98xZQrXZ/AoE7Y+X2TRLe8rrSNyBn4vU7m2o3v37u57XaFCBf/xeLXs5aJjp3nz5rE+zmXnzp3uvKJzj84lynQe6Pz5875KlSq5bPTt2rXzjRw50lenTh3/+WD8+PFX3MZt27a541sjAKxdu9Z3rX799VeXNV8Pfa5ChQr5n2teIJ2H9N3s2rWr+/7q+NLzyMtpxIZUqVK5MtU+e+WVV1y56HNGFox1et/rn3766Zr3D4DQR9ANANGgwEcXV4EX85Fp+C0FXt5QWxqCSUGkLrxef/31KF+ji2EFGrqg18WcggBdpOuiWsMsRSew+vDDD10gp9ffcsstLsiMatgtbbvWoYtwDR/UqFEj/xBDgwYNirDsvn373LLafn0mBWp3332374MPPrjqvvK29fPPP/dvly5Sowo4fvzxRxdkpEyZ0nfzzTe711xuyLDLfX4NR6ahsHTTQ++lIF7LakinmATdomHaqlSp4ob5yZs3rwuSvSHgvOW2bt3qe+qpp3w33XST+05of9asWTPKi2sNzXTnnXe6YFUPlY+2Tfv9Srx9sH79et9DDz3kgid9NxQgnTp1KtZBd3T2l2jIqp49e7oAUmWjAEuBiILvyAFcZApC69ev7/abgkLve3mlIdb0/VdQrpsC0eGV3VdffeW2U4Gaykzvq88X6HIBc3TL+0rriGrYO72/hnrTjQ3tN9240s2G6AbdCv4Dh/eK6XHuueOOO9w83TiJim6e6AaOvlsaClDnL+0PvUY3Ga9E34HA78u18j5HVI/I3199/7t06eLOSdoXuuEV1c0c0XCM+t7qONX3Xd/zwCHmgrlO3XQpWLBghGEKASReSfQPFf4AkDipL2K5cuVck8nHHnssTtappqYaemjkyJFxsr7EqG/fvq5puprzK0N6uNN3UBm5vREAEjN1ubjxxhtt8ODBLhHZ9aTm6srmvmDBApejALGj5unKXdCjRw976aWX2I0A6NMNAIlFVOPIDh8+3PX1DUwkBVxP6r+smz/KZI7/23dYmeOHDBlySQb1YJ4P1K9ZOQOUTKx8+fIUxTVQf3Bll3/++efZjwAcspcDQCKhmrMVK1a4IXyUwErDWenx7LPPXjI8GRBsStSn76OGX1NCrsjJvhIzDVmmRzC1b9/eBd5K3qaaWSWKVBb+AQMGMMTVNVKwTcANIBBBNwAkEsqiO3v2bHvttddctt2CBQu6ZsyRhzIDrgdl+Nb42DfffLN99dVXbkgsXD+1atVyNzymTp1qp0+ftiJFiriabo3EAACIW/TpBgAAAAAgSBinGwAAAACAICHoBgAAAAAgSOjTHUeUYXT37t2WIUMGN1wOAAAAACB8afTt48ePW968ed1oMJdD0B1HFHCT/RcAAAAAEpedO3da/vz5LzufoDuOqIbb2+Ea4xIAAAAAEL6OHTvmKl69WPByCLrjiNekXAE3QTcAAAAAJA5X615MIjUAAAAAAIIk3oPuf/75x1q0aGHZsmWzNGnSWKlSpey3336L0Dm9d+/elidPHje/du3atnnz5gjrOHTokD322GOuhjlz5szWunVrO3HiRIRl/vjjD6tWrZqlTp3aNQEYPHjwJdsyadIku+WWW9wy2o7p06cH8ZMDAAAAAMJdvAbdhw8ftjvuuMNSpEhhM2bMsPXr19tbb71lWbJk8S+j4Pidd96xMWPG2NKlSy1dunRWt25dO336tH8ZBdzr1q2z2bNn29SpU23evHn27LPPRmhrX6dOHbvhhhtsxYoVNmTIEOvbt6998MEH/mUWLVpkzZs3dwH7qlWrrFGjRu6xdu3a67hHAAAAAADhJIlPVcnxpEePHrZw4UKbP39+lPO1aUq/3rlzZ+vSpYubdvToUcuVK5eNHz/emjVrZhs2bLASJUrY8uXLrWLFim6ZmTNnWr169WzXrl3u9aNHj7ZXXnnF9u7daylTpvS/9+TJk23jxo3uedOmTe3kyZMuaPdUqVLFypYt6wL+q1FgnylTJrd99OkGAAAAgPAW3RgwXmu6f/jhBxcoP/zww5YzZ04rV66cjR071j9/27ZtLlBWk3KPPlTlypVt8eLF7rn+qkm5F3CLltc4aaoZ95apXr26P+AW1ZZv2rTJ1bZ7ywS+j7eM9z6RnTlzxu3kwAcAAAAAAAkm6N66daurhS5atKjNmjXL2rRpYy+++KJ98sknbr4CblHNdiA99+bprwL2QMmTJ7esWbNGWCaqdQS+x+WW8eZHNnDgQHcDwHswRjcAAAAAIEEF3RcvXrTy5cvbgAEDXC23+mE/88wz0WrOHd969uzpmhF4D43PDQAAAABAggm6lZFc/bEDFS9e3Hbs2OH+nzt3bvd33759EZbRc2+e/u7fvz/C/PPnz7uM5oHLRLWOwPe43DLe/MhSpUrlH5ObsbkBAAAAAAku6FbmcvWrDvTnn3+6LONSuHBhF/TOmTPHP199p9VXu2rVqu65/h45csRlJffMnTvX1aKr77e3jDKanzt3zr+MMp3ffPPN/kzpWibwfbxlvPcBAAAAACCkgu6OHTvakiVLXPPyLVu22JdffumG8Wrbtq2bnyRJEuvQoYO9/vrrLunamjVrrGXLli4juYbz8mrG7733XtcsfdmyZS4bert27Vxmcy0njz76qEuipuHANLTYxIkTbcSIEdapUyf/trz00ksu67mGLFNGcw0ppvHCtS4AAAAAAEJuyDDREF3qH71582ZXs61AWAG0R5vXp08fF4yrRvvOO++09957z4oVK+ZfRk3JFRxPmTLFZS1v0qSJG9s7ffr0/mX++OMPF8xraLHs2bNb+/btrXv37hG2ZdKkSdarVy/bvn27S+6mMcI19Fh0hMqQYYV6TIvvTUjUtg+qH9+bAAAAACAORDcGjPegO1wQdCM6CLoBAACA8BAS43QDAAAAABDOCLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAACBKCbgAAAAAAgoSgGwAAAACAICHoBgAAAAAgSAi6AQAAAAAIEoJuAAAAAACChKAbAAAAAIAgIegGAAAAACBICLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAACBKCbgAAAAAAgoSgGwAAAACAICHoBgAAAAAgSAi6AQAAAAAIEoJuAAAAAACChKAbAAAAAIAgIegGAAAAACBICLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAACBKCbgAAAAAAwjHo7tu3ryVJkiTC45ZbbvHPP336tLVt29ayZctm6dOntyZNmti+ffsirGPHjh1Wv359S5s2reXMmdO6du1q58+fj7DML7/8YuXLl7dUqVJZkSJFbPz48Zdsy6hRo6xQoUKWOnVqq1y5si1btiyInxwAAAAAkBjEe033rbfeanv27PE/FixY4J/XsWNHmzJlik2aNMl+/fVX2717tzVu3Ng//8KFCy7gPnv2rC1atMg++eQTF1D37t3bv8y2bdvcMjVr1rTVq1dbhw4d7Omnn7ZZs2b5l5k4caJ16tTJ+vTpYytXrrQyZcpY3bp1bf/+/ddxTwAAAAAAwk0Sn8/ni8+a7smTJ7tgOLKjR49ajhw57Msvv7SHHnrITdu4caMVL17cFi9ebFWqVLEZM2ZYgwYNXDCeK1cut8yYMWOse/fuduDAAUuZMqX7/7Rp02zt2rX+dTdr1syOHDliM2fOdM9Vs33bbbfZyJEj3fOLFy9agQIFrH379tajR49ofZZjx45ZpkyZ3HZnzJjREqpCPabF9yYkatsH1Y/vTQAAAAAQB6IbA8aqpvuvv/6yXr16WfPmzf21wQqA161bF+N1bd682fLmzWs33nijPfbYY665uKxYscLOnTtntWvX9i+rpucFCxZ0Qbfob6lSpfwBt6iGWh/e2xYtE7gObxlvHaol13sFLpM0aVL33FsmKmfOnHHvE/gAAAAAAOCagm4181agu3TpUvv222/txIkTbvrvv//ummfHhGqY1RxcNc6jR492TcGrVatmx48ft71797qa6syZM0d4jQJszRP9DQy4vfnevCstoyD51KlTdvDgQddMPaplvHVEZeDAge6uhvdQzTgAAAAAANcUdKu59euvv26zZ892QbGnVq1atmTJkhit67777rOHH37YSpcu7Wqfp0+f7pp9f/3115bQ9ezZ0zUj8B47d+6M700CAAAAAIR60L1mzRp78MEHL5muzOGqNb4WqtUuVqyYbdmyxXLnzu2afisID6Ts5Zon+hs5m7n3/GrLqM19mjRpLHv27JYsWbIol/HWERVlQtc6Ah8AAAAAAFxT0K3AWFnGI1u1apXly5fProWaqqu/eJ48eaxChQqWIkUKmzNnjn/+pk2bXJ/vqlWruuf6q5sAgVnGVQOvALhEiRL+ZQLX4S3jrUO19XqvwGWUSE3PvWUAAAAAALguQbcyfysjuPo7a1xtBagLFy60Ll26WMuWLWO0Lr1GfcS3b9/uhvxSDbpqnZWgTf2kW7du7Yby+vnnn12ysyeffNIFwspcLnXq1HHB9eOPP+76lGsYMCV409jeqomW559/3rZu3WrdunVz2c/fe+8913xdw5F59B5jx451Q45t2LDB2rRpYydPnnTvBwAAAABAbCWP6QsGDBjgglolDlMCMgW9+vvoo4+6gDcmdu3a5QLsf//91w0Pduedd7p+4fq/DBs2zGUSb9KkicsWrn7fCpo9CtCnTp3qgmQF4+nSpbNWrVpZ//79/csULlzYDRmmIHvEiBGWP39+GzdunFuXp2nTpm6IMY3vrZsJZcuWdcndIidXAwAAAADguozTrcRhatqtJuHlypWzokWLWmLGON2IDsbpBgAAABJXDBjjmm6ParoZJgsAAAAAgDjs062m3m+++eYl0wcPHuyG/wIAAAAAALEMuufNm2f16tWLcsxtzQMAAAAAALEMutWHW8NsRabhvdSmHQAAAAAAxDLoLlWqlE2cOPGS6RMmTPCPjQ0AAAAAAGKRSO3VV1+1xo0b219//WW1atVy0+bMmWNfffWVTZo0iX0KAAAAAEBsg+7777/fJk+e7Mbr/t///mdp0qSx0qVL208//WQ1atSI6eoAAAAAAAhbsRoyrH79+u4BAAAAAADisE83AAAAAACIw5rurFmz2p9//mnZs2e3LFmyWJIkSS677KFDh6L51gAAAAAAhLdoBd3Dhg2zDBkyuP8PHz482NsEAAAAAEDiCbpbtWrl/p4/f97VctetW9dy5coV7G0DAAAAACDx9OlOnjy5Pf/883b69OngbREAAAAAAIk1kVqlSpVs1apVwdkaAAAAAAAS85BhL7zwgnXu3Nl27dplFSpUsHTp0kWYrzG7AQAAAABALILuZs2aub8vvviif5r6eft8Pvf3woUL7FcAAAAAAGITdG/bto0dBwAAAABAMILuG264IaYvAQAAAAAgUYpx0C2bNm2yd9991zZs2OCeFy9e3Nq3b28333xzXG8fAAAAAACJJ+j+5ptvXL/uihUrWtWqVd20JUuWWMmSJW3ChAnWpEmTYGwngGgo1GMa+ykebR9Un/0PAACAawu6u3XrZj179rT+/ftHmN6nTx83j6AbAAAAAIBYjtO9Z88ea9my5SXTW7Ro4eYBAAAAAIBYBt133XWXzZ8//5LpCxYssGrVqsV0dQAAAAAAhK0YNy9v2LChde/e3VasWGFVqlTx9+meNGmS9evXz3744YcIywIAAAAAkFgl8fl8vpi8IGnS6FWOJ0mSxC5cuGCJxbFjxyxTpkx29OhRy5gxoyVUJNoK70RblG/8IpEaAABA4nEsmjFgjGu6L168eK3bBgAAAABAohDjPt0AAAAAACB6CLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAICEF3X/99Zf16tXLmjdvbvv373fTZsyYYevWrYv1hgwaNMgNM9ahQwf/tNOnT1vbtm0tW7Zslj59emvSpInt27cvwut27Nhh9evXt7Rp01rOnDmta9eudv78+QjL/PLLL1a+fHlLlSqVFSlSxMaPH3/J+48aNcoKFSpkqVOntsqVK9uyZcti/VkAAAAAAIhV0P3rr79aqVKlbOnSpfbtt9/aiRMn3PTff//d+vTpE6u9unz5cnv//fetdOnSEaZ37NjRpkyZYpMmTXLvu3v3bmvcuLF/vsYBV8B99uxZW7RokX3yyScuoO7du7d/mW3btrllatasaatXr3ZB/dNPP22zZs3yLzNx4kTr1KmT2/6VK1damTJlrG7duv4bCgAAAAAAXJegu0ePHvb666/b7NmzLWXKlP7ptWrVsiVLlsR4AxS0P/bYYzZ27FjLkiWLf7oGGP/www/t7bffduuuUKGCffzxxy649t7nxx9/tPXr19vnn39uZcuWtfvuu89ee+01V2utQFzGjBljhQsXtrfeesuKFy9u7dq1s4ceesiGDRvmfy+9xzPPPGNPPvmklShRwr1GNecfffRRjD8PAAAAAACxDrrXrFljDz744CXT1bT74MGDMV2daz6umujatWtHmL5ixQo7d+5chOm33HKLFSxY0BYvXuye669q3XPlyuVfRjXUx44d8zd11zKR161lvHUoONd7BS6TNGlS99xbJipnzpxx7xP4AAAAAADgmoLuzJkz2549ey6ZvmrVKsuXL1+M1jVhwgTXnHvgwIGXzNu7d6+rSdf7BVKArXneMoEBtzffm3elZRQknzp1yt0oUDP1qJbx1hEVbXOmTJn8jwIFCsToswMAAAAAwl+Mg+5mzZpZ9+7dXUCqxGcXL160hQsXWpcuXaxly5bRXs/OnTvtpZdesi+++MIlLws1PXv2dE3gvYc+DwAAAAAA1xR0DxgwwDXzVs2u+mOrD3T16tXt9ttvdxnNo0tNupWoTFnFkydP7h5KlvbOO++4/6umWU2/jxw5EuF1yl6eO3du93/9jZzN3Ht+tWUyZsxoadKksezZs1uyZMmiXMZbR1SUCV3rCHwAAAAAAHBNQbeafCvp2datW23q1KkuidnGjRvts88+c8FrdN19992uf7gyinuPihUruqRq3v9TpEhhc+bM8b9m06ZNboiwqlWruuf6q3UEZhlXgjcFwLoZ4C0TuA5vGW8d+jxK0ha4jGrv9dxbBgAAAACA2Egeq1eZuZpuPdQfWoHv4cOHI2Qfv5oMGTJYyZIlI0xLly6dG5Pbm966dWs3lFfWrFldIN2+fXsXCFepUsXNr1OnjguuH3/8cRs8eLBr8q7adiVnU020PP/88zZy5Ejr1q2bPfXUUzZ37lz7+uuvbdq0af731Xu0atXKBfqVKlWy4cOH28mTJ102cwAAAAAArlvQrXGulTFcAbEC7ho1arhhvDTElmq+77rrLosrGtZLmcSbNGnisoUr6/h7773nn6+adb1nmzZtXDCuoF3Bc//+/f3LaLgwBdga83vEiBGWP39+GzdunFuXp2nTpnbgwAE3vrcCdw0/NnPmzEuSqwEAAAAAEBNJfD6fLyYvUNA6efJkVyusvy+88IL98ssvrnm5apGVVC0xUjZ0ZTFXUrWE3L+7UI//X8OP62/7oPpBXT/lG97lCwAAgNCLAWPcp1tDbHkJxqZPn26PPPKIFStWzDXdVjNzAAAAAAAQy6BbTa7Xr1/vmparCfY999zjpv/3338xSqQGAAAAAEC4i3GfbiUXU+12njx53DjdtWvXdtOXLl3qhhIDAAAAAACxDLr79u3rsovv3LnTHn74YX+WcNVy9+jRI6arAwAAAAAgbMVqyLCHHnrokmnKGg4AAAAAAK4x6NYY1r/++qvt2LHDzp49G2Heiy++GJtVAgAAAAAQdmIcdK9atcrq1avnEqcp+M6aNavLaK5xunPmzEnQDQAAAABAbLOXd+zY0e6//347fPiwpUmTxpYsWWJ///23VahQwYYOHRrT1QEAAAAAELZiHHSvXr3aOnfubEmTJnXJ086cOWMFChSwwYMH28svvxycrQQAAAAAIDEE3SlSpHABt6g5ufp1S6ZMmVxGcwAAAAAAEMs+3eXKlbPly5db0aJFrUaNGta7d2/Xp/uzzz5zQ4kBAAAAAIBY1nQPGDDA8uTJ4/7/xhtvWJYsWaxNmzZ24MAB++CDD2K6OgAAAAAAwlaMa7orVqzo/7+al8+cOTOutwkAAAAAgMQ7TjcA4Por1GMauz0ebR9Un/0PAACC37x837599vjjj1vevHktefLkLoN54AMAAAAAAMSypvuJJ55wGctfffVV17c7SZIkMV0FAAAAAACJQoyD7gULFtj8+fOtbNmywdkiAAAAAAASa/PyAgUKmM/nC87WAAAAAAAQRmIcdA8fPtx69Ohh27dvD84WAQAAAACQmJqXayzuwL7bJ0+etJtuusnSpk1rKVKkiLDsoUOH4n4rAQAAAAAI16BbtdsAAAAAACAIQXerVq1iuFoAAAAAABDjPt3Tp0+3WbNmXTL9xx9/tBkzZrBHAQAAAACIbdCtJGoXLly4ZPrFixfdPAAAAAAAEMuge/PmzVaiRIlLpt9yyy22ZcuWmK4OAAAAAICwFeOgO1OmTLZ169ZLpivgTpcuXVxtFwAAAAAAiS/ofuCBB6xDhw72119/RQi4O3fubA0bNozr7QMAAAAAIPEE3YMHD3Y12mpOXrhwYfcoXry4ZcuWzYYOHRqcrQQAAAAAIFyHDIvcvHzRokU2e/Zs+/333y1NmjRWunRpq169enC2EAAAAACAxBB0nzt3zgXZq1evtjp16rgHAAAAAACIg+blKVKksIIFC0Y5ZBgAAAAAALjGPt2vvPKKvfzyy3bo0CG7VqNHj3ZN0zNmzOgeVatWtRkzZvjnnz592tq2bev6i6dPn96aNGli+/bti7COHTt2WP369S1t2rSWM2dO69q1q50/fz7CMr/88ouVL1/eUqVKZUWKFLHx48dfsi2jRo2yQoUKWerUqa1y5cq2bNmya/58AAAAAIDELcZB98iRI23evHmWN29eu/nmm10wG/iIifz589ugQYNsxYoV9ttvv1mtWrVcdvR169a5+R07drQpU6bYpEmT7Ndff7Xdu3db48aN/a9XjbsC7rNnz7p+5p988okLqHv37u1fZtu2bW6ZmjVrumbxyrz+9NNP26xZs/zLTJw40Tp16mR9+vSxlStXWpkyZaxu3bq2f//+mO4eAAAAAAD8kvh8Pp/FQL9+/a44X4HrtciaNasNGTLEHnroIcuRI4d9+eWX7v+yceNGlyl98eLFVqVKFVcr3qBBAxeM58qVyy0zZswY6969ux04cMBSpkzp/j9t2jRbu3at/z2aNWtmR44csZkzZ7rnqtm+7bbb3A0FuXjxohUoUMDat29vPXr0iNZ2Hzt2zCWZO3r0qKu1T6gK9ZgW35uQqG0fVD+o66d84xflG96CXb4AACC0RDcGjHH28msNqi9Htdaq0T558qRrZq7abyVuq127tn8ZDVOmPuVe0K2/pUqV8gfcohrqNm3auNrycuXKuWUC1+EtoxpvUS253qtnz57++UmTJnWv0Wsv58yZM+4RuMMBAAAAALim5uVxbc2aNa6/tvpbP//88/bdd99ZiRIlbO/eva6mOnPmzBGWV4CteaK/gQG3N9+bd6VlFCSfOnXKDh486AL+qJbx1hGVgQMHursa3kM14wAAAAAAXFPQrVrgZMmSXfYRU+oXrr7WS5cudTXUrVq1svXr11tCp5pxNSPwHjt37ozvTQIAAAAAJDAxbl6umuhAagK+atUql8Tsav29o6LabGUUlwoVKtjy5cttxIgR1rRpU9f0W32vA2u7lb08d+7c7v/6GznLuJfdPHCZyBnP9Vxt7jXmuHezIKplvHVERTXzegAAAAAAEGdBt7KLR6ZEZ7feeqvLAt66dWu7Fkpipr7SCsA1LvicOXPcUGGyadMmN0SY+nyL/r7xxhsuy7iGC5PZs2e7gFpN1L1lpk+fHuE9tIy3DgX9ei+9T6NGjfzboOft2rW7ps8CAAAAAEjcYhx0X44Smz377LMxbqJ93333ueRox48fd5nKNaa2hvNSP2kF8BrKSxnNFUgrm7iCZb2X1KlTxwXXjz/+uA0ePNj1we7Vq5cb29urhVY/cWUl79atmz311FM2d+5c+/rrr11Gc4/eQ83aK1asaJUqVbLhw4e7hG5PPvlkXO0eAAAAAEAiFCdBtxKSvfPOO5YvX74YvU411C1btrQ9e/a4ILt06dIu4L7nnnvc/GHDhrk+5KrpVu23so6/9957/terWfjUqVNdX3AF4+nSpXPBc//+/f3LFC5c2AXYGvNbzdY1Nvi4cePcujxqyq4hxjS+twL3smXLuuHEIidXAwAAAAAgqON0Z8mSxZIkSeJ/rperljpt2rT2+eefW8OGDS0xYpxuRAfjOIc3yje8MU43AAC4LuN0q+l1INVE58iRwypXruwCcgAAAAAAEMugW823AQAAAABAkPp0Hz582D788EPbsGGDe65kZko6poRnAAAAAADg/0pqMTRv3jwrVKiQS5ym4FsP/V8JyzQPAAAAAADEsqZbw3Ep2/fo0aNd9nC5cOGCvfDCC27emjVrYrpKAAAAAADCUoxrurds2WKdO3f2B9yi/2usa80DAAAAAACxDLrLly/v78sdSNPKlCkT09UBAAAAABC2Yty8/MUXX7SXXnrJ1WpXqVLFTVuyZImNGjXKBg0aZH/88Yd/2dKlS8ft1gIAAAAAEM5Bd/Pmzd3fbt26RTkvSZIk5vP53F/19QYAAAAAILGKcdC9bdu24GwJAAAAAACJPei+4YYbgrMlAAAAAAAk9kRqAAAAAAAgegi6AQAAAAAIEoJuAAAAAACChKAbAAAAAICEFHQfOXLExo0bZz179rRDhw65aStXrrR//vknrrcPAAAAAIDEk738jz/+sNq1a1umTJls+/bt9swzz1jWrFnt22+/tR07dtinn34anC0FAAAAACDca7o7depkTzzxhG3evNlSp07tn16vXj2bN29eXG8fAAAAAACJJ+hevny5Pffcc5dMz5cvn+3duzeutgsAAAAAgMQXdKdKlcqOHTt2yfQ///zTcuTIEVfbBQAAAABA4gu6GzZsaP3797dz586550mSJHF9ubt3725NmjQJxjYCAAAAAJA4gu633nrLTpw4YTlz5rRTp05ZjRo1rEiRIpYhQwZ74403grOVAAAAAAAkhuzlylo+e/ZsW7BggctkrgC8fPnyLqM5AACInUI9prHr4tH2QfXZ/wCAhBF0e+688073AAAAAAAAcRR0v/POO1FOV99uDSGmpubVq1e3ZMmSxXTVAAAAAAAk7qB72LBhduDAAfvvv/8sS5Ysbtrhw4ctbdq0lj59etu/f7/deOON9vPPP1uBAgWCsc0AAAAAAIRnIrUBAwbYbbfdZps3b7Z///3XPTRcWOXKlW3EiBEuk3nu3LmtY8eOwdliAAAAAADCtaa7V69e9s0339hNN93kn6Ym5UOHDnVDhm3dutUGDx7M8GEAAAAAgEQvxjXde/bssfPnz18yXdP27t3r/p83b147fvx4ot+5AAAAAIDELcZBd82aNe25556zVatW+afp/23atLFatWq552vWrLHChQvH7ZYCAAAAABDuQfeHH35oWbNmtQoVKliqVKnco2LFim6a5okSqr311ltXXdfAgQNd//AMGTJYzpw5rVGjRrZp06YIy5w+fdratm1r2bJlc+tVE/Z9+/ZFWEb9yOvXr++SuWk9Xbt2vaQ2/pdffnHjiWt71Rx+/Pjxl2zPqFGjrFChQi4Lu/qoL1u2LKa7BwAAAACA2AfdSpI2e/ZsW79+vU2aNMk99P8ff/zRcuXK5a8Nr1OnzlXX9euvv7qAesmSJW6d586dc687efKkfxklZJsyZYp7Hy2/e/dua9y4sX/+hQsXXMB99uxZW7RokX3yyScuoO7du7d/mW3btrlltF2rV6+2Dh062NNPP22zZs3yLzNx4kTr1KmT9enTx1auXGllypSxunXrumzsAAAAAADERhKfz+ezBEJDkammWsG1xvo+evSo5ciRw7788kt76KGH3DIbN2604sWL2+LFi61KlSo2Y8YMa9CggQvGvaB/zJgx1r17d7e+lClTuv9PmzbN1q5d63+vZs2a2ZEjR2zmzJnuuWq2Ves+cuRI9/zixYtuyLP27dtbjx49rrrtx44ds0yZMrltzpgxoyVUhXpMi+9NSNS2D6of1PVTvvGL8g1vlG94C3b5AgDCT3RjwBhnL5ddu3bZDz/84Jp1q4Y50Ntvv22xpY0VNVWXFStWuNrv2rVr+5e55ZZbrGDBgv6gW39LlSrlD7hFNdTqY75u3TorV66cWyZwHd4yqvEWfQa9V8+ePf3zkyZN6l6j1wIAAAAAEBsxDrrnzJljDRs2tBtvvNHVOpcsWdK2b99uqjBXn+nYUs2yguA77rjDrVOUDV011ZkzZ46wrAJsL1O6/gYG3N58b96VltGdiVOnTtnhw4ddM/WoltFnjMqZM2fcw6N1AQAAAABwTX26VRvcpUsXl6FcCcc0ZvfOnTutRo0a9vDDD1tsqW+3mn9PmDDBQoGSwKkpgfdQU3QAAAAAAK4p6N6wYYO1bNnS/T958uSuplhZxfv3729vvvmmxUa7du1s6tSp9vPPP1v+/PkjJG1T02/1vQ6k7OWa5y0TOZu59/xqy6jdfZo0aSx79uyWLFmyKJfx1hHVzQc1h/ceuvEAAAAAAMA1Bd3p0qXz9+POkyeP/fXXX/55Bw8ejNG61CRdAfd3331nc+fOvWRsbw1LliJFCtek3aMhxdSXvGrVqu65/qrWPTDLuDKhK6AuUaKEf5nAdXjLeOtQE3a9V+Ayau6u594ykWnoMb1H4AMAAAAAgGvq063kZQsWLHAZxOvVq2edO3d2Qe+3337r5sW0Sbkyk3///fdurG6vD7aaa6sGWn9bt27thvJScjUFtsomrkDYey8NMabg+vHHH7fBgwe7dfTq1cutW4GxPP/88y4rebdu3eypp55yAf7XX3/tMpp79B6tWrVyY45XqlTJhg8f7oYue/LJJ2O6iwAAAAAAiF3QrezkJ06ccP/v16+f+7/GuC5atGiMM5ePHj3a/b3rrrsiTP/444/tiSeecP8fNmyYyyTepEkTl7hMWcffe+89/7JqFq6m6cpWrmBcNfEKntXc3aMadAXYGvN7xIgRrgn7uHHj3Lo8TZs2dUOMaXxvBe5ly5Z1w4lFTq4GAAAAAEBQxulWhu+FCxda6dKlL8kontgxTjeig3F+wxvlG94o3/DGON0AgAQxTrdqldWcW8nUCLoBAACip1CP/9+lDdcXN1QAhFwiNY2hvXXr1uBsDQAAAAAAiTnofv3119043epHvWfPHlelHvgAAAAAAACxTKSmjOXSsGFDS5IkiX+6uobrufp9AwAAAACAWATdP//8M/sNAAAAAIBgBN01atSI6UsAAAAAAEiUYtynW+bPn28tWrSw22+/3f755x837bPPPrMFCxbE9fYBAAAAAJB4gu5vvvnG6tata2nSpLGVK1famTNn3HSNTTZgwIBgbCMAAAAAAIkne/mYMWNs7NixliJFCv/0O+64wwXhAAAAAAAglkH3pk2brHr16pdMz5Qpkx05ciSmqwMAAAAAIGzFOOjOnTu3bdmy5ZLp6s994403xtV2AQAAAACQ+ILuZ555xl566SVbunSpG5d79+7d9sUXX1iXLl2sTZs2wdlKAAAAAAASw5BhPXr0sIsXL9rdd99t//33n2tqnipVKhd0t2/fPjhbCQAAAABAYgi6Vbv9yiuvWNeuXV0z8xMnTliJEiUsffr0wdlCAAAAAAASS/Pyzz//3NVwp0yZ0gXblSpVIuAGAAAAACAugu6OHTtazpw57dFHH7Xp06fbhQsXYroKAAAAAAAShRgH3Xv27LEJEya4ZuaPPPKI5cmTx9q2bWuLFi0KzhYCAAAAAJBYgu7kyZNbgwYNXMby/fv327Bhw2z79u1Ws2ZNu+mmm4KzlQAAAAAAJIZEaoHSpk1rdevWtcOHD9vff/9tGzZsiLstAwAAAAAgsdV0ixKpqaa7Xr16li9fPhs+fLg9+OCDtm7durjfQgAAAAAAEktNd7NmzWzq1Kmullt9ul999VWrWrVqcLYOAAAAAIDEFHQnS5bMvv76a9esXP8PtHbtWitZsmRcbh8AAAAAAIkn6Faz8kDHjx+3r776ysaNG2crVqxgCDEAAAAAAK6lT7fMmzfPWrVq5YYMGzp0qNWqVcuWLFkS29UBAAAAAJC4a7r37t1r48ePtw8//NCOHTvm+nSfOXPGJk+ebCVKlAjeVgIAAAAAEM413ffff7/dfPPN9scff7hs5bt377Z33303uFsHAAAAAEBiqOmeMWOGvfjii9amTRsrWrRocLcKAAAAAIDEVNO9YMEClzStQoUKVrlyZRs5cqQdPHgwuFsHAAAAAEBiCLqrVKliY8eOtT179thzzz1nEyZMsLx589rFixdt9uzZLiAHAAAAAADXkL08Xbp09tRTT7ma7zVr1ljnzp1t0KBBljNnTmvYsGFMVwcAAAAAQNiK9ZBhosRqgwcPtl27drmxugEAAAAAQBwF3Z5kyZJZo0aN7IcffojxWN/Kiq5m6kmSJHFDjwXy+XzWu3dvNxZ4mjRprHbt2rZ58+YIyxw6dMgee+wxy5gxo2XOnNlat25tJ06ciLCMMq5Xq1bNUqdObQUKFHA3CiKbNGmS3XLLLW6ZUqVK2fTp02P0WQAAAAAACErQHVsnT560MmXK2KhRo6Kcr+D4nXfesTFjxtjSpUtd0/a6deva6dOn/cso4F63bp3rVz516lQXyD/77LP++RpPvE6dOnbDDTfYihUrbMiQIda3b1/74IMP/MssWrTImjdv7gL2VatWuRsIeqxduzbIewAAAAAAEM6iPWRYMNx3333uERXVcms88F69etkDDzzgpn366aeWK1cuVyPerFkz27Bhg82cOdOWL19uFStWdMto7PB69erZ0KFDXQ36F198YWfPnrWPPvrIUqZMabfeequtXr3a3n77bX9wPmLECLv33nuta9eu7vlrr73mgnhlaFfADwAAAESlUI9p7Jh4tH1QffY/Erx4DbqvZNu2bbZ3717XpNyTKVMmN1zZ4sWLXdCtv2pS7gXcouWTJk3qasYffPBBt0z16tVdwO1Rbfmbb75phw8ftixZsrhlOnXqFOH9tUzk5u4AAAAAEg9uqsSv7WFyUyXBBt0KuEU124H03Junv8qaHih58uSWNWvWCMsULlz4knV48xR06++V3icqZ86ccY/AZuwAAAAAACSYPt2hbODAga7m3XsoQRsAAAAAACERdOfOndv93bdvX4Tpeu7N09/9+/dHmH/+/HmX0TxwmajWEfgel1vGmx+Vnj172tGjR/2PnTt3XsOnBQAAAACEowQbdKtJuILeOXPmRGjCrb7aVatWdc/198iRIy4ruWfu3Ll28eJF1/fbW0YZzc+dO+dfRknSNMa4mpZ7ywS+j7eM9z5RSZUqlRumLPABAAAAAECCCbo1nrYyievhJU/T/3fs2OHG7e7QoYO9/vrrbvzvNWvWWMuWLV1Gcg3nJcWLF3dZx5955hlbtmyZLVy40Nq1a+eSrGk5efTRR10SNQ0HpqHFJk6c6LKVByZOe+mll1wW9Lfeess2btzohhT77bff3LoAAAAAAAjJRGoKbGvWrOl/7gXCrVq1svHjx1u3bt3cWN4a2ks12nfeeacLjlOnTu1/jYYEU3B89913u6zlTZo0cWN7e9Tf+scff7S2bdtahQoVLHv27Na7d+8IY3nffvvt9uWXX7rhyV5++WUrWrSoy1xesmTJ67YvAAAAAADhJ16D7rvuusuNx305qu3u37+/e1yOMpUrYL6S0qVL2/z586+4zMMPP+weAAAAAACEfZ9uAAAAAABCHUE3AAAAAABBQtANAAAAAECQEHQDAAAAABAkBN0AAAAAAAQJQTcAAAAAAEFC0A0AAAAAQJAQdAMAAAAAECQE3QAAAAAAEHQDAAAAABBaqOkGAAAAACBICLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAACBKCbgAAAAAAgoSgGwAAAACAICHoBgAAAAAgSAi6AQAAAAAIEoJuAAAAAACChKAbAAAAAIAgIegGAAAAACBICLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAACBKCbgAAAAAAgoSgGwAAAACAICHoBgAAAAAgSAi6Ixk1apQVKlTIUqdObZUrV7Zly5YFa98DAAAAAMIcQXeAiRMnWqdOnaxPnz62cuVKK1OmjNWtW9f2798ffyUEAAAAAAhZBN0B3n77bXvmmWfsySeftBIlStiYMWMsbdq09tFHH8VfCQEAAAAAQhZB9/9z9uxZW7FihdWuXfv/75ykSd3zxYsXx1f5AAAAAABCWPL43oCE4uDBg3bhwgXLlStXhOl6vnHjxkuWP3PmjHt4jh496v4eO3bMErKLZ/6L701I1IL9/aB84xflG94o3/BG+YYvyja8Ub7h7VgCj6287fP5fFdcjqA7lgYOHGj9+vW7ZHqBAgViu0okApmGx/cWIJgo3/BG+YY3yjd8UbbhjfINb5lC5Nr5+PHjlilTpsvOJ+j+f7Jnz27JkiWzffv2RdhBep47d+5LdlzPnj1d0jXPxYsX7dChQ5YtWzZLkiRJ3JUgItxJ0k2NnTt3WsaMGdkzYYbyDW+Ub3ijfMMXZRveKN/wRvkGn2q4FXDnzZv3issRdP8/KVOmtAoVKticOXOsUaNG/kBaz9u1a3fJjkuVKpV7BMqcOXPclSAuSwE3QXf4onzDG+Ub3ijf8EXZhjfKN7xRvsF1pRpuD0F3ANVct2rVyipWrGiVKlWy4cOH28mTJ102cwAAAAAAYoqgO0DTpk3twIED1rt3b9u7d6+VLVvWZs6ceUlyNQAAAAAAooOgOxI1JY+qOTnin5rz9+nT55Jm/QgPlG94o3zDG+Ubvijb8Eb5hjfKN+FI4rtafnMAAAAAABArSWP3MgAAAAAAcDUE3QAAAAAABAlBNwAAAAAAQULQDQAAAABAkBB0AwAAAAAQJATdSFBIpg+EBo7V8Hfx4sX43gQAwBV+g//77z/2T4gg6EaCOGmcPXvW/U2SJAklAoRAMOYdqwMHDrQxY8bE9yYhCJIm/b+XCJMmTbItW7awj8PUsmXLbOXKlfG9GQgibqCF37WzfoOnTJlir776qp0/fz6+NwnRQNCNeD9pTJ8+3Z555hlr0qSJLV682E6cOEGphCl++MOjDL1gbN26dbZ69Wp74YUXbOLEifG9aQiC9evXW/fu3W3Dhg3u+YULF9jPYXQs//vvv9agQQPbvn17fG8O4rgyY9euXbZt2zbbuXOn/5yN0PXtt9/aTz/95P7v3fSeO3eupU2b1pInT07rsxDAUYh4o5PG/Pnz7ZFHHrFkyZK5H4ZGjRrZhx9+aAcPHqRkwuBHf8WKFfb555+7mtDDhw/zwx8GvIu3Hj16WKtWrdxxnD9/fmvevLl9/PHH8b15iGMlSpSwcuXK2YABA9xznasRPjfPsmXLZsWLF3e/v0K3kfCozFCAVrNmTatdu7YVK1bMOnToYL/99lt8bx5iSTfFXnnlFRs1apS7bvbouKWlaOgg6Ea8n0h69uxpH330kWvipov44cOH26effkrgHQY/+g0bNrRhw4bZ2LFj3YXd8uXL43vzEAfU3HjkyJHuoWP1l19+sS5duljr1q1t/Pjx7OMwaYniXczpHH3q1CmbOnWqe05gFrq8sjt58qR/Wq5cuWzJkiXu/zp30yIpdKn85s2bZ48//rgLtL/88kt3fTVr1ix7++23bdWqVfG9iYiFQoUK2TvvvOOui3WNrN9cSZkypWXOnDlCKyQdv5yjE6bk8b0BSJwB2e+//2579uxxzVNvuukm//zBgwe7vzq56C78o48+ajlz5ozHLUZMqXx//fVX12VA5alAbNOmTS7obty4sX3yySdWq1YtdmwI0931MmXKWJUqVdzzG2+80QVm6hry1FNPWbp06ezhhx/2H+8IrVYM33//vd13333+Wm2dozNkyGA//PCDa4pMmYYulZ2apHbu3Nkdt7qYz5gxox09etT+/PNPVytKU+TQbr2gLnuq5W7btq2bXrlyZXcd9fzzz9uECRNcyxXOzaFDwbSO23vuucf9tnbs2NEF3ilSpHABt3cN7Z2v9R04dOiQZc2aNZ63HJEl8XE7BNfZN9984+7C5s2b17Zu3eou7lQTqueel19+2dWiDRo0yP1QcBEQOk6fPm1Dhw51PxR9+vRxAdqdd95p9957r+s/qLvw+g5Uq1YtvjcVsfTZZ5+5C7o//vjDXbR7F3A//vijK2f54osvXJNzhBaVqS7u0qdP77r+KNdGxYoVXc2KylNlryarCF3Tpk2zHTt2uO4/e/fudf9fu3atVapUybVoUJeCokWLuue6yYKE7dy5cy4AUxZr9e9t3769u4Gi2m0l2NK5WQGZuu516tTJNm/eTGVGCNJvapEiRdz/FXjrmll9vHWtVapUKXftpf+rrDXvq6++cjdLkXAQdOO6+ueff9wddtV0Pvjgg65/yv/+9z/3w64finz58vmX7du3r7Vo0cJ/kkHoUJ8j3ZFV2dWtW9dKly5t77//vutTpgu51KlT28yZM6169erxvamIZtK0wJoRXdCpRvvWW291SbZUYyZr1qxxN8ty5MjhmjTOnj3bLYPQKGPvucpafbiVJE9Nyl988UW74YYbbOnSpe7irlu3bv6LOyR83rEbuay9MlTLBv3WqtuIztEKwpVATzkaFHwjYVKSNAXbyqnx3Xffuabj/fv3d+Wmlmbqsle+fHl/Oes3V9dfaomWPXv2+N58xODY1fFYsmRJ13pQXbn026qs5WfOnHHXVy1btnS126rYUKCtclfrQiQsNC/HdaMhSXQhp7ux6uurC3MF1vrRUOCtCwL1QfJqvDUPofOjEBiUebXYukhXv1CvmZvKulmzZu5uPN0GEjaVp3eBrhsmqh3RzRLVlKgJqvIvKLBWQrXnnnvOJWRSohc1d3v22Wdt3Lhx7jUE3QlXYBCmC3FdwKmm84EHHnAXdPoOKBBTyxRd5KkWXOdndRlReSPh887LqhFT0KUuXSrfO+64w91AkRo1argb3mqO2qtXLzdN5231F0XCpFpN1XZqxJd+/fq5ESTUCkUUgKmWWze8Z8yYYRUqVHDT1a0gVapULtM1QoOOXbVIUTnr2FTALWqNpBspOk8rP0OmTJns7rvvju/NxdWoeTlwPbz77ru+W265xZc9e3bf33//HWHe66+/7rvtttt8L7zwgm/37t0USIi4ePGi+zt37lxfmzZtfP379/fNnj3bP//rr7/2JU2a1Pfnn3/6zp8/73v11Vd9DzzwgO/MmTPxuNWIbrlKnz59fOnSpfM99NBDvrRp0/oqVKjgW7JkiZv32Wef+e6//35fkiRJfMWKFfOVK1fOd+HCBd+JEyd8JUqU8E2bNo2dHQK6d+/uu+mmm3zly5f35c6d21e3bl3f+vXr/d+Dw4cP+7Zv3+5r3769r0iRIr433njjku8JEq5vv/3WHbtdu3b1tWvXzlejRg1f6dKlfXv27HHz//vvP1/hwoV9w4cP97+Gsk34Nm7c6CtevLgvRYoUvrfffttNO3v2rPur39zmzZv7kidP7qtSpYrvzjvv9GXOnNm3cuXKeN5qxMTevXt9tWvX9qVJk8ZdHweWsfz444++atWquWUWLFjAzk3gCLpxXX300UfuR6JJkybuIi7Qyy+/7Ktevbpv3759lEoImTlzpvthVzCtC7c77rjDN2zYMP98lakuCipWrOjLkCGDb9WqVfG6vYg+HaONGzf2LV261D0/deqUC6z1WLRokX85lemmTZv8F+qdO3d2Qfg///zD7g6Bm6E5cuTw/fbbb+75mDFj3E2UefPm+ctTN8w8CrwVtCE07Nq1yx2v7733nnt+8OBBF3zpGBWvjBs0aODr0aMHwXaIBWS6ntINs5tvvtlfmRF4w2TChAm+fv36+QYNGuQCcYSer776yl1X5cuXzx3Pcu7cOf/86dOn++rUqePbuXNnPG4looOgG0HhnfSPHj3qar1Onjzpnzdq1Ch3Z+6xxx7z7dixI8LrdEGA0KEf+b59+/pGjx7tnm/evNn34osvuou8IUOGuGmq+Xzrrbd877zzDj/6IUQ3TlSrqZsmgT/mx44dczWiqvH+9ddfI/z4//LLL75nn33WlzVrVmpUEiDvgi2QWqi8+eab7v8TJ050AZl3PKsG1OPVrvzxxx++/Pnzu1o2JDyRa6h1M6xo0aK+/fv3+7Zt2+bK7plnnvHP/+mnn9wxrfPz2rVr42GLcS1lrRubv//+u++uu+5y52sv8PbOy7RYCA/fffeda7GgcvZ+jwN/ewOvsZFwMU43gtaHTBlSle1Ww1OoH6jGbRb1PWratKn9/fffrj+K/nroJxg61L/ziSeecP3xle1WlDhN/fKVIE2ZNjVGt/qMqvyVKI+kPKHjoYcecllx1ZdMCXu8Y1tJWtT/V+WqvoNKnubJnTu3ZcmSxRYuXOiOeyQc6m+v43TDhg3+acpsvHz5ctdXX+WsvtoDBw50I0Yo+ZLyakycONGfj0E05JDO7yRiSpi8vBobN270Z7VWWWnYRg0jpdFCRo8e7ZZR/26Vr5bV+Zn8CwmbN9iQhlxVn20lLFWOBSXSUoKtAgUKuL6+u3btcv2233rrLZdYTd8DBipK+LwyUjJDJSTVqD4qY2nUqJG7jhLlU1FSYpWxzuGSJk2aeNxyRFt8R/0ITz/88IPrg/Laa6+5JuXNmjVzd2E/+eQT/zKqTSlZsqSrGQu8Y4fQsGLFCl/Dhg1dk/HA5uSiGpVOnTr5ChUq5JqvImFTa4SoqM9nnjx5XMsU9fENpFYsTz75ZISmx8KxnDD9+++/rl+nmqEGlqVaHqllSsqUKX0ffvihf7r6catvt/JtBOrSpYtv+fLl13XbcXVbtmzxPfLII+7/33zzjWtyvG7dOve8Zs2arstA69atI7ymW7durtuP17cbodM/X8exyvSll15yrQlFx+Xdd9/tS58+vbvm0nzVgiPh81ok6NjNmTOnO1erlZm6aX3++ecR8uSo/7Zam9F9K/QQdOOaHTp06JLmbGXLlvW9//777vmRI0d8uXLlcgF25MB77Nixl/TtRuhQU1Nd6OkHIPCHwbsI7Nmzp2/r1q3xtn2IWcCtfrxqYrxs2TJ340TUlE3Hr5q1bdiwIcp1RA68kbB4N0IUSOtiTudhL/BWf31d3FWqVMm3cOFCN01NVOvVq+erXLmy/7WXuzGDhEFlp4SHKjMFW0pyGNitQNNLlSrlmzJlirtwV7CmG6YEZaETkKn7ncrx448/dufn77//3pc6dWpfq1at3E1Q0fVU7969XRcC76YLQoN+f/Vb63XvmT9/vjumVcbetMAEplw7hx6CblwT1WKrJiwwQYeSe7Rt29YlRNMFu/qTqd+gAjTdVS9QoIBL1oPQ+9FXGSojte6262aKrFmzxt1VV6KPyIE3tZ6hQ5mN1d+zYMGCroWCgjD19xQdxzrOVYui7wBCky7MdZNUx6oCb+8migKxWrVquczlmq6ab/Uf9Ppxc1MlNGj0CAXcKj+PV3Z//fWX75577nE1ZxpFRK0YVq9eHY9bi5gmLO3YsaMLsHXzzPPzzz+7oOyJJ56IMJ3f3tC4rvKurVReGilELQRF+Y5uuOEGX4sWLdyIA6lSpYpwfaU8DAg9BN24JgqsVatdpkwZl0TL4wVkOlk0bdrUf4JQ8zYF3VWrVnU/ECT5CB2TJk1yd2HVbFHBmS7QdSEgqi3R8CSqDQ1sooqEK7DmUjUn2bJlc3fadaxqGBL92Cv4VnI0UVM2XdDrmEZo0PB93lBCGm7mqaeecv/XuVeBt45lL/DW+VvLjxw50jdjxgx/sMbFe8IW+BuqVioaBUS/scpm7Am8aaLjWL/bx48fv+7bitjTOVrnX/0GewlovXO4Au+MGTO6YR29ZLRcWyVMXplpJBCP1xpQN7f1G6ykaLpGfvrpp910DdGpGysqf7UORegi6MY1nzx0AadaETVdU9PywPkaWibwIl013hoLlCzloUXDCWXKlMn98Kupoh4KyvRD79WGqo93/fr1fffee6+/qRsSHl2Ye7yAShnnNZpAINVoN2rUyPfoo4/6L9B13FLrGRpUZupzf9ttt7kaTjUlDsxOHVXgHRllnbB5gZVueupGiXKp6NyrUQVUrir3QBrmL3CMX4RGk/IzZ864/6tbgIbn1NBukbOT60apWiPt3r07Hrca0aGbJrp+Ui6FyZMnu2urwNEg1L1LXfa887KuqzV0p4Z9Y9SI0EbQjWsOunUhp+EMdBdOfQO9puaar35jCsg1HImazah21BvSAgmb92OuclTfMXUN0AVd4B101W6rVsULytTUPKphiZAwqBx1nKoZauTkWOorGHnYEQ31plYNkfM2EIyFTvI0NTVWmXfv3v2S8vP6eKu5Md0GQrcFkoboU4szlbPKUze2FXirq4BqvNX/95VXXnFjOpM0LXQo+FLCNN1M8W6WjB8/3pcsWTLfq6++6j+Ovd/kwCH+kHApWZqOU10bq9n4l19+GWH+ggUL3LGsgFzUekUVGl4LUoQuhgxDrGnIoO+++85uv/12W7RokTVo0MANLdSkSRPbsmWLm//www/bjTfeaMOHD7eff/7Zpk+fbgULFmSvh8jQM1OmTLERI0bYzp073VBDGTNmdNNPnz7tlunTp49dvHjRDTskJUuWtHz58sXzluNyKleubEOHDnVDuWk4KI+GCjp48KA7Pv/77z//9FKlSlmOHDns1KlTEdaTLFkydnICpyG/dJxqOKHGjRvbggUL3HnYKz8NI5Q5c2Z3jMvrr78ez1uMmFq1apW1adPGDRc1d+5c2717t/u9/f77792Qjp999pkbKqxWrVr28ccf26effuqG9UNoqFixovvN7dWrl/3000/umNVwUR9++KENGDDAHbM6zr1h4hg2KjSGBNP5uE6dOrZ06VL321ulShX/fD00tKOGb2zWrJmVL1/e3n33XXvjjTcsU6ZM8fwJcK2SKPK+5rUgUTpw4IALuJ988kl7+eWX3cn/r7/+cicK/ThMnjzZbrrpJjt+/LidPXvW/TBkzZo1vjcbl6GAK3/+/O4i3RtrXTdNatSo4cq4QoUKVrt2bXfhrvEhRTdX6tat6y7m7rjjDvZtAqbjU8GWAuiPPvrIHbO6aeKN/ambZbqI13jO1apVcxd7GodbN89mzJjhv7BDwqUbYCqvyDSma79+/dyY6jo/v/TSS/55hw4dcmM5p02blpspIebLL790F+MaYz1DhgzuGN27d6917tzZlbkCcR3vmq8LeY3pjITL+92NTDdNVK4ad1u/wTpeP//8c3d+VuCtczlCp3z1Oztp0iRLly6dzZs3z90s0Xjqgdde27dvtxUrVrgKD1VoFSlSJL43H3GAmm7E2vnz591Dd2PdlylpUitWrJi7EPj333/t2WeftY0bN7qLgWzZshFwJ2D79u2zdu3auYB6/fr1/h9+TdcNlFSpUtlTTz1lq1evtvbt27saNF0EqCZFPxKFCxeO74+AK1AZebXTn3zyiTsuNa1Lly722muvuenffPONu3Gilg1ly5a1e++91x3HqgnV90EBHRIulacXcL///vvWsWNHd1Nlx44drvVJt27d3EWdLvaGDBnizt26gFf56xyt74duzCB0qLzPnDnjWqfoGFWZqiZbgbgu5mfPnu0u7FXOBNwJn8pQN0gUlAXSzZNcuXK53945c+a4SowWLVq4a60HH3ww3rYX0ecF02odqsoMHbu6wf3EE0+4iqlXX33VtU7xrr2OHj3qboR36NCBgDucxHf7doQ2DQemrLiBlJWxZs2ark+KMjCSuCU0KBGaki4pY6b6Zov6A3rjqu/fv983dOhQ18dMyVyUOE999PU6hIZevXr5cuTI4fviiy/ccH8tW7Z0CbbUP9CzatUqN4SUEvOQwTr0MtGr77bKuHbt2r7SpUu7nAte8p0tW7a4pHmFCxd2w9HoGPaSNCH0qDzVJ1THdSCN31uyZEmX9RihQedaHcc33nijG9ZN5+HISpQo4foBa8hOjtvQM3XqVF+aNGl8H3zwQYTcRsqJpKSHGntbo4X07dvXncNJOBx+CLoRLV6iDl28LV++3A1RIUqQpkQ9SrgUSON0z5071/34I3SsXLnSZc3U0EIKvDXcm5ed3KMLAw1boQs6b+gSJHz6AddNsMAhRzR80Ouvv+4uBJQZNSokTQsdGgqqffv27jj2klzWq1fPlzlzZn/grezGymKtGy/cVAl9Grs3ZcqULqO1hn3Td0BJ03SzRcc3QuPayhvxQ0lJlfBOv8M6jgMTl+p3WZUZGnXgxIkT8bbNiDlVRj388MMuKZooaamSDg8ePNg3a9YsV6HRsGFDX968ed1NUSXRQ/ihTzei0xrCNXlRH201WVT/E/U3UXPjRx55xDVL/fXXX13CByWH0P/VhFFNpAoUKMAeDjEqN3UNUIIPlW3OnDldch59D9TEWM1Q1fdbTVhTpkwZ35uLaFJztVtuucXatm3rEvN41PdTzd2WLFliPXr0cAl6EHrUx1NJtdR393//+5//3Ku8C+rDrWaretx8881R9vVHaNJ5eeLEie6cnSVLFkudOrVrbq5kavpNRsK3bNky119b11dKqnXixAkrV66cy6sxduxY1y1EeVR69uxp9evXd8loSUgbWpRboXr16la1alWXxFRdf5Rj488//3TnX52j9Tu8f/9+1xWEhLThiaAb0fLjjz9a06ZN7c0333R9UNSvSCd//dArMc/mzZvtvffec32N1P9XiZrULxShaeXKla6c1e9IwbeSpR05csQlXVL5NmzY0E1H6CTU0jT121dffPX5LF68uH+eAnH119dFu9eHG6FFo0Po/Lxw4UJbt26duyj3bpgqwaUu6KdOner6eOumGcLL33//7XI16CaKgjTKOHR88cUXblQJjf7x4osv2m233eYCb/1VgkP91bH81VdfuZwrlG1oUsLZ559/3iXCu/vuu61Ro0YuGZ4C7rVr17rrbG6AhjeCblzVsWPHrGvXru7OW+/evd2wYPfcc48LqpWopV69eq52TMm0lBBCF3np06dnz4Y4BWG6qVKmTBmX8KNQoULxvUmIYcCtYd6UXElDf4lqv1Sbfd9997khSXTjRBd3jz/+uD3wwAPuRsuVsugi4d5UUZn99ttvrrZb52wF3xruzStLDR01btw4GzhwoH/0AQAJw4QJE2zUqFEuoNaIEgq01WJBN0o1FJwqNJToVDdUELp000Sty3QN7Z3HVcY6Z6tVgyo1EL4IunFVOtl7TdVUE6ZMqPq/LuB05/Wxxx5zzcpV061myAivpubPPfecK1c1hwqsHUXCpuBamcoVdOmGmZofq/yUcV61KvqxV0ZcDf2nwFytG3SXnYA7dAJuZcLVBbmm6SJO3QdUjqotO3z4sKv9VveQyGWq8ibwBuKPWiUowAoc+UPZyMeMGeOaF+v8rYoNbxxuZalnHO7w+w7o91g3WxYsWOBaOiC8MWQYrkr9du+//3435rbGclafMfVJEf0YaBxnnTy4iAs/6lemHwQ1Sc6cOXN8bw6uIHBIrx9++MHlVdCdc/2oq2+ggjL121at9gcffOCauWl4IbVU0Xig3pBR1HAnbF7ArSHA1C3gl19+cd15Hn30UfdXN0QHDx7shmnUDVIdu5HLlHM1EH927drl+u8OGjTI5cfx6Bh++umnXTNjHcPLly9352Ud8wTc4UW/uRqbWzdOlQeJgDtxoKYbMaIxXb/++ms3BqhqvZXYQ7Voqg1VPxWEJ43LrZstSPhUo62kaRpfXWN8imo61RpFzc2VZEvJeiKj9jN0qIWRgm5dsFWsWNE+/vhjdxNF0xs3buxPzqT+gpqv7wSA+OO1NtFYzOqq9eGHH7rj9fbbb3d9egNrvKtVq+YSbCl3ysiRI2lyHKaJ1dQdSN8FEg4nHnTsQow0aNDAJWFSzbeCMN2JnT9/PgF3mCPgDg0nT550eRdUe+IF3KKLPdWeKCGeEh+q2bkyqQbWgFL7GTqUkVzlp4BaLRpU1iNGjHABt/roKwNupUqV3A0WuoQACWcEGFVQqA/vq6++6qZ7N8R0DCsA0w1uHbPKu6GbZvTxDU9quaCbK0hcqOlGjGnYGfXfzpQpk0vaQxZrIOFc2O3Zs8eaN2/u+vpOmzbNihYtGqFPr5of6+Lu22+/je9NRiyTpqm/p5qd6uanug0MGTLE1XSrnMePH+9GGVC/bq/1EcOCAfFL52I1KX/nnXfczU+vdlPXUroJqprue++913XV0wgSak2oLiIAwgdBN2J9IaiLePp/AgkjGAt8rn68urDTcwXXuqALDLyjCuSQ8AQGyxr2S7UjykiuFkZ33nmnm64xmnUx77V0UG23+gdq3F8A8U+116q11g1QtRRUVnL161ZwrWRpai2oMZuXLl1q2bNn9+dmABBeuOpC7L44SZMScAPxJDBoVlI01Woq8NLFmwI1JUhTc3It16RJE9fcPPAGmV4bmHgNCcvo0aPdyAFewN29e3fXtUfDBSk5mvqFavQIJblU332N0ayLdpW1stFrvG4ACYNueGqoVQ2pqlYoOp41HKdujGmYxnTp0rk+3mpFOGfOHAJuIExR0w0AIUrNjJWdXM0SdWGnIWfUt/eRRx5xiQ7Vt1fzVPOtbKl58uSJ703GVejiXP211adTF+cKsF944QU3lNCRI0ds3bp1ronqk08+6fp+ahmVtYZ/099Zs2a5ZuU0KQcSjk8//dR1AdGxeffdd1ujRo1c7beSqK1du9Ydt+TVAMIbidQAIASpH6Cy36qJopoiLlq0yPXnVUIe1aho6BmN0ay+hArO9X8kfOoKoDJV+b377rtufF5lKn/ggQfc/GPHjrk++SpTlb+C8J07d7ph4cqUKeNaMZCJHkhYvJEE/vnnH5eHwWtppJtj+fPnd38JuoHwRk03AISAwD7ZGm5EQbcCLDVT1LjcGn/7/fffd5mt1W9w6NChLlN5YDIeaj9Dx8qVK12mY/Xl7tSpk/Xq1cs/799//7XWrVu7ZEwKzAPRXx9I+JQwTa2URo0aZQsWLGCcZiARIOgGgBAKuD3r16+3DBkyuCBL47mqubFquTVdNSpK3vPFF1+4TOYITeqnrbLNmjWr68Ndrlw5/zzVhCtD/fTp0+N1GwHEjLr6qD/36tWrXWsVtVABEP5IpAYACZwXcCurrWo9pUSJEq6mU1lwpVatWu6vgvDOnTvbxx9/7M9qjdBUqlQp+/77710LheHDh7uLdFH3gQ0bNrhmqQBCi87dGm5V/bgJuIHEg5puAAgBGmbm5Zdftrlz57phofr27eumq//vgw8+6GpMihUrZq+88oobWmrSpEluPv17Q58ymbdo0cIOHz7sWjGkSpXKNTvXEENKzBRVSwgAAJBwEHQDQAIUVSC1b98+GzlypEuOpiGk+vfv76YrK66GDrvhhhtcH24NPaNgDOFDGY51cyV16tTWtWtXe+yxx9yQYtxUAQAg4SPoBoAEHHD/9ttvrnYzMPDWkFEzZ860+vXr+wPvefPmuRpQLUswFp6WL1/u+nZr+DB9P0iaBgBAaCDoBoAEGnCrRrt37972xBNPWPv27f3L7Nmzx/r16+eylmt6z549I6yDLOXh//0g4AYAIHQQdANAAqQ+2r/88osbp3nz5s2uT6+S7wQOKVWnTh03bJhqu9XEHIkDfbgBAAgtZC8HgARGw319+umndvbsWTe0TPHixd243KNHj/Yvo2BbQfegQYPcWN1IPEiaBgBAaKGmGwASYC2m+nLXrFnTNTEvWrSovfrqq27c5ho1alizZs1clvKCBQv6+/fSpBwAACBhIugGgATYVPjYsWP29NNPW+7cuV3iNDUx//LLL+399993Q4JpupqfM2QUAABAwkbQDQAJwLBhw1xyrKZNm1r+/PndtLFjx1qHDh1s9erVrrb71KlTdvz4cfvnn3+sTJkyrok5Q0YBAAAkbATdABDPFEwrG7maileoUMEKFSpkQ4YMsbRp07ra7owZM9rw4cNdrXZgrTgZrAEAABI+gm4ASCB27dplM2bMcMH3f//9Z5UqVbJ///3XzZswYYKlT5+ezNUAAAAhhqAbABIgNS1ft26d688tr732mkueBgAAgNBC0A0ACTix2vLly23UqFF24MABN3a3mpoDAAAgdBB0A0ACt3TpUjdU2I8//mjVq1eP780BAABADCSNycIAgOtf8125cmUrV66cbd++nd0PAAAQYgi6ASABU1PzDz74wNV233HHHfG9OQAAAIghmpcDQAL3119/2ZkzZ6xEiRLxvSkAAACIIYJuAAAAAACChOblAAAAAAAECUE3AAAAAABBQtANAAAAAECQEHQDAAAAABAkBN0AAAAAAAQJQTcAAEgw49JPnjw5vjcDAIA4RdANAEAi9MQTT7gg13tky5bN7r33Xvvjjz/ie9MAAAgrBN0AACRSCrL37NnjHnPmzLHkyZNbgwYNLrv8uXPnruv2AQAQDgi6AQBIpFKlSmW5c+d2j7Jly1qPHj1s586dduDAAdu+fburAZ84caLVqFHDUqdObV988YX9+++/1rx5c8uXL5+lTZvWSpUqZV999VWE9d5111324osvWrdu3Sxr1qxu/X379o2wzObNm6169epuvSVKlLDZs2df508PAMD1kfw6vQ8AAEjATpw4YZ9//rkVKVLENTU/efKkm65A/K233rJy5cq5APn06dNWoUIF6969u2XMmNGmTZtmjz/+uN10001WqVIl//o++eQT69Spky1dutQWL17smrPfcccdds8999jFixetcePGlitXLjf/6NGj1qFDh3j89AAABA9BNwAAidTUqVMtffr07v8KsvPkyeOmJU36/xvCKRhWgByoS5cu/v+3b9/eZs2aZV9//XWEoLt06dLWp08f9/+iRYvayJEjXRN2Bd0//fSTbdy40b0ub968bpkBAwbYfffdF/TPDADA9UbQDQBAIlWzZk0bPXq0+//hw4ftvffec4HvsmXL/MtUrFgxwmsuXLjgAmQF2f/884+dPXvWzpw545qaB1LQHUgB/f79+93/N2zYYAUKFPAH3FK1atWgfEYAAOIbQTcAAIlUunTpXHNyz7hx4yxTpkw2duxYe/rpp/3LBBoyZIiNGDHChg8f7vpza75qwxV8B0qRIkWE5+ofrmblAAAkNgTdAADAHxirafmpU6cuu0cWLlxoDzzwgLVo0cI9VyD9559/umRo0VW8eHGXsE1Z01UDLkuWLKEUAABhiezlAAAkUmoWvnfvXvdQk2/1z1ZCtfvvv/+yr1H/bGUaX7RokXvNc889Z/v27YvR+9auXduKFStmrVq1st9//93mz59vr7zyShx8IgAAEh6CbgAAEqmZM2e6mmY9KleubMuXL7dJkya5Ib8up1evXla+fHmrW7euW07DgTVq1ChG76va9O+++87VqCv5mpqyv/HGG3HwiQAASHiS+Hw+X3xvBAAAAAAA4YiabgAAAAAAgoSgGwAAAACAICHoBgAAAAAgSAi6AQAAAAAIEoJuAAAAAACChKAbAAAAAIAgIegGAAAAACBICLoBAAAAAAgSgm4AAAAAAIKEoBsAAAAAgCAh6AYAAAAAIEgIugEAAAAAsOD4Px+kdZ1SU0VkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 2.785 s\n",
      "RSS Δ: +2.44 MB\n",
      "Peak memory Δ: +2.56 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb59d9640, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 2cfb59dbfb0, raw_cell=\"# codecell_37c (keep this id for tracking purposes..\" transformed_cell=\"# codecell_37c (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_37c (keep this id for tracking purposes)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "avg_price_by_brand_pdf = avg_price_by_brand_df.toPandas()\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(avg_price_by_brand_pdf[\"brand_code\"], avg_price_by_brand_pdf[\"avg_price\"])\n",
    "plt.xlabel(\"Brand\")\n",
    "plt.ylabel(\"Average purchase price\")\n",
    "plt.title(\"Average purchase price by brand (avg > 10000)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740f635",
   "metadata": {},
   "source": [
    "## 4. Load RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c86140-8287-4d48-9eff-1b16281174fd",
   "metadata": {},
   "source": [
    "The remaining exercises focus on RDD manipulations.\n",
    "\n",
    "Let's start by loading the RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3411a973-b7cc-4f31-9e6b-cebaef3196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RDDs directly from DataFrames (with required repartitions)\n",
    "# type: RDD[Row]\n",
    "events_rdd   = events_df.rdd.repartition(1000)\n",
    "products_rdd = products_df.rdd.repartition(100)\n",
    "brands_rdd   = brands_df.rdd.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1e1c0-de17-4e17-985c-3d4329d207b2",
   "metadata": {},
   "source": [
    "You'll need `Row`, so let's make sure we've imported it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c291905f-5ec5-442a-b06b-d7fa03e9f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92b878-6f10-4bd6-90c2-624c3bedd41b",
   "metadata": {},
   "source": [
    "## 5. Implementations of Computing Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b6453",
   "metadata": {},
   "source": [
    "In this next exercise, we're going to implement \"computing the mean\" (version 1) and (version 3) in Spark as described in the second lecture **Batch Processing I** (please use ctrl+f to reach the slide with the title : \"Computing the Mean: Version 1\" or \"Computing the Mean: Version 3\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad895c-719c-4c09-b72a-27e890f78f1e",
   "metadata": {},
   "source": [
    "To make the problem more tractable (i.e., to reduce the running times), let's first do a bit of filtering of the `events` table.\n",
    "We'll do this using DataFrames, and then generate an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b0d9982-816f-49f7-9960-91835e2011a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in events          table: 42351862\n",
      "Number of rows in filtered events table: 664885\n"
     ]
    }
   ],
   "source": [
    "filtered_events_df = (\n",
    "    events_df\n",
    "        .filter((F.col(\"event_type\") == \"purchase\") & F.col(\"price\").isNotNull())\n",
    "        .join(brands_df, on=\"brand_key\")\n",
    ")\n",
    "\n",
    "filtered_events_df.count()\n",
    "\n",
    "print(f\"Number of rows in events          table: {events_df.count()}\")\n",
    "print(f\"Number of rows in filtered events table: {filtered_events_df.count()}\")\n",
    "\n",
    "filtered_events_rdd = filtered_events_df.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffa9e2-e05d-45ab-9885-0a071a6156dd",
   "metadata": {},
   "source": [
    "You can confirm that we're working with a smaller dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9f80ad-13a2-49ca-bbef-495be02c15d5",
   "metadata": {},
   "source": [
    "Compute the average purchase price by brand. We want the results sorted by the average purchase price from the largest to smallest value. As before, round to two digits after the decimal point. This is similar to Q7 above, except _without_ the \"more than 10K\" condition.\n",
    "\n",
    "Implement using the naive **\"version 1\"** algorithm, as described in the lectures:\n",
    "\n",
    "+ You _must_ start with `filtered_events_rdd`.\n",
    "+ You _must_ use `groupByKey()`.\n",
    "+ Per \"version 1\", your implementation _must_ shuffle all values from the \"mappers\" to the \"reducers\".\n",
    "\n",
    "**write some code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e73f28d7-f55b-454b-9273-3609a0d10f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 110.0 failed 1 times, most recent failure: Lost task 15.0 in stage 110.0 (TID 540) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 21 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 21 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (s / c) \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     39\u001b[39m avg_by_brand = (\n\u001b[32m     40\u001b[39m     grouped\n\u001b[32m     41\u001b[39m     .mapValues(avg_iter)\n\u001b[32m     42\u001b[39m     .filter(\u001b[38;5;28;01mlambda\u001b[39;00m kv: kv[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     43\u001b[39m     .mapValues(\u001b[38;5;28;01mlambda\u001b[39;00m avg: \u001b[38;5;28mround\u001b[39m(avg, \u001b[32m2\u001b[39m))\n\u001b[32m     44\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m average_revenue_per_brand_v1 = \u001b[43mavg_by_brand\u001b[49m\u001b[43m.\u001b[49m\u001b[43msortBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mkv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m average_revenue_per_brand_v1.take(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1440\u001b[39m, in \u001b[36mRDD.sortBy\u001b[39m\u001b[34m(self, keyfunc, ascending, numPartitions)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msortBy\u001b[39m(\n\u001b[32m   1401\u001b[39m     \u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[T]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1402\u001b[39m     keyfunc: Callable[[T], \u001b[33m\"\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1403\u001b[39m     ascending: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1404\u001b[39m     numPartitions: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1405\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mRDD[T]\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1406\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1407\u001b[39m \u001b[33;03m    Sorts this RDD by the given keyfunc\u001b[39;00m\n\u001b[32m   1408\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1436\u001b[39m \u001b[33;03m    [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\u001b[39;00m\n\u001b[32m   1437\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1439\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeyBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[type-var]\u001b[39;49;00m\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43msortByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumPartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1441\u001b[39m         .values()\n\u001b[32m   1442\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1376\u001b[39m, in \u001b[36mRDD.sortByKey\u001b[39m\u001b[34m(self, ascending, numPartitions, keyfunc)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mapPartitions(sortPartition, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# first compute the boundary of each part via sampling: we want to partition\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# the key-space into bins such that the bins have roughly the same\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# number of (key, value) pairs falling into them\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m rddSize = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rddSize:\n\u001b[32m   1378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# empty RDD\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2183\u001b[39m, in \u001b[36mRDD.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[33;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[32m   2165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2181\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2158\u001b[39m, in \u001b[36mRDD.sum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[NumberOrArray]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mNumberOrArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[32m   2140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2156\u001b[39m \u001b[33;03m    6.0\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2159\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1911\u001b[39m, in \u001b[36mRDD.fold\u001b[39m\u001b[34m(self, zeroValue, op)\u001b[39m\n\u001b[32m   1906\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[32m   1908\u001b[39m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[32m   1909\u001b[39m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 110.0 failed 1 times, most recent failure: Lost task 15.0 in stage 110.0 (TID 540) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 21 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 21 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 3.747 s\n",
      "RSS Δ: +14.15 MB\n",
      "Peak memory Δ: +12.70 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb5a69ca0, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 110.0 failed 1 times, most recent failure: Lost task 15.0 in stage 110.0 (TID 540) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n",
       "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 21 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fulfill(Iterator.scala:242)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n",
       "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 21 more\n",
       " info=<ExecutionInfo object at 2cfb5a6a660, raw_cell=\"# codecell_5x1 (keep this id for tracking purposes..\" transformed_cell=\"# codecell_5x1 (keep this id for tracking purposes..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# codecell_5x1 (keep this id for tracking purposes)\n",
    "\n",
    "# TODO: Write your code below, but do not remove any lines already in this cell.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Version 1 groupByKey()\n",
    "\n",
    "Objectif:\n",
    "- Implémenter le calcul de la moyenne du prix par marque en utilisant groupByKey(),\n",
    "\n",
    "Problème :\n",
    "- groupByKey() rassemble toutes les valeurs associées à une clé (ici tous les prix\n",
    "  d’une marque) avant le calcul.\n",
    "- Sur un jeu de données volumineux, cette approche peut entraîner une forte\n",
    "  consommation mémoire et provoquer l’échec de l’exécution en environnement local.\n",
    "- Cette version est je pense correcte d’un point de vue algorithmique.\n",
    "\n",
    "Conclusion :\n",
    "- Je vais laisser cette implémentation qui aurait marcher sans ces problèmes.\n",
    "- Une version plus efficace et adaptée aux grands volumes de données est proposée\n",
    "  après avec reduceByKey().\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "pairs = filtered_events_rdd.map(lambda r: (r[\"brand_code\"], float(r[\"price\"])))\n",
    "\n",
    "grouped = pairs.groupByKey()\n",
    "\n",
    "def avg_iter(prices_it):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for x in prices_it:\n",
    "        s += float(x)\n",
    "        c += 1\n",
    "    return (s / c) if c else None\n",
    "\n",
    "avg_by_brand = (\n",
    "    grouped\n",
    "    .mapValues(avg_iter)\n",
    "    .filter(lambda kv: kv[1] is not None)\n",
    "    .mapValues(lambda avg: round(avg, 2))\n",
    ")\n",
    "\n",
    "average_revenue_per_brand_v1 = avg_by_brand.sortBy(\n",
    "    lambda kv: (-kv[1], kv[0])\n",
    ")\n",
    "\n",
    "average_revenue_per_brand_v1.take(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221f4d7-4b39-4849-a9f2-d185a26a3209",
   "metadata": {},
   "source": [
    "Compute the average purchase price by brand. We want the results sorted by the average purchase price from the largest to smallest value. As before, round to two digits after the decimal point. This is similar to Q7 above, except _without_ the \"more than 10K\" condition.\n",
    "\n",
    "Implement using the improved **\"version 3\"** algorithm, as described in the lectures:\n",
    "\n",
    "+ You _must_ start with `filtered_events_rdd`.\n",
    "+ You _must_ use `reduceByKey()`.\n",
    "+ Per \"version 3\", your implementation _must_ emit `(sum, count)` pairs and take advantage opportunities to perform aggregations.\n",
    "\n",
    "**write some code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "024fbcb8-c5bc-4d3c-b22d-f2b99b9b40be",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 112.0 failed 1 times, most recent failure: Lost task 13.0 in stage 112.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\r\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\r\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\r\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\r\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\r\n\t... 20 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m     price = \u001b[38;5;28mfloat\u001b[39m(e[\u001b[33m\"\u001b[39m\u001b[33mpurchase_price\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;66;03m# <-- adapte ici\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (brand, (price, \u001b[32m1\u001b[39m))\n\u001b[32m     17\u001b[39m average_revenue_per_brand_v3 = (\n\u001b[32m     18\u001b[39m     \u001b[43mfiltered_events_rdd\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_brand_sum_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduceByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# (sum, count)\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# avg arrondi\u001b[39;49;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43msortBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# tri décroissant sur avg\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1440\u001b[39m, in \u001b[36mRDD.sortBy\u001b[39m\u001b[34m(self, keyfunc, ascending, numPartitions)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msortBy\u001b[39m(\n\u001b[32m   1401\u001b[39m     \u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[T]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1402\u001b[39m     keyfunc: Callable[[T], \u001b[33m\"\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1403\u001b[39m     ascending: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1404\u001b[39m     numPartitions: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1405\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mRDD[T]\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1406\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1407\u001b[39m \u001b[33;03m    Sorts this RDD by the given keyfunc\u001b[39;00m\n\u001b[32m   1408\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1436\u001b[39m \u001b[33;03m    [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\u001b[39;00m\n\u001b[32m   1437\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1439\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeyBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[type-var]\u001b[39;49;00m\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43msortByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumPartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1441\u001b[39m         .values()\n\u001b[32m   1442\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1376\u001b[39m, in \u001b[36mRDD.sortByKey\u001b[39m\u001b[34m(self, ascending, numPartitions, keyfunc)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mapPartitions(sortPartition, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# first compute the boundary of each part via sampling: we want to partition\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# the key-space into bins such that the bins have roughly the same\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# number of (key, value) pairs falling into them\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m rddSize = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rddSize:\n\u001b[32m   1378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# empty RDD\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2183\u001b[39m, in \u001b[36mRDD.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[33;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[32m   2165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2181\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2158\u001b[39m, in \u001b[36mRDD.sum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[NumberOrArray]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mNumberOrArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[32m   2140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2156\u001b[39m \u001b[33;03m    6.0\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2159\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1911\u001b[39m, in \u001b[36mRDD.fold\u001b[39m\u001b[34m(self, zeroValue, op)\u001b[39m\n\u001b[32m   1906\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[32m   1908\u001b[39m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[32m   1909\u001b[39m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 112.0 failed 1 times, most recent failure: Lost task 13.0 in stage 112.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\r\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\r\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketException: Connection reset\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\r\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\r\n\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\r\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\r\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\r\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\r\n\t... 20 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 17.752 s\n",
      "RSS Δ: +0.64 MB\n",
      "Peak memory Δ: +0.64 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 10e9e361e50, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 112.0 failed 1 times, most recent failure: Lost task 13.0 in stage 112.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n",
       "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.net.SocketException: Connection reset\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n",
       "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\n",
       "\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\n",
       "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\n",
       "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\n",
       "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n",
       "\t... 20 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n",
       "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.net.SocketException: Connection reset\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n",
       "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)\n",
       "\tat java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)\n",
       "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)\n",
       "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:399)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:208)\n",
       "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n",
       "\t... 20 more\n",
       " info=<ExecutionInfo object at 10e9e361d30, raw_cell=\"# average purchase price by brand (v3: emit (sum, ..\" transformed_cell=\"# average purchase price by brand (v3: emit (sum, ..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "# average purchase price by brand (v3: emit (sum, count) and aggregate early)\n",
    "\n",
    "# 1) events -> (brand, (price, 1))\n",
    "#    ⚠️ adapte les index/keys selon la structure de tes events\n",
    "#    Exemple si event est un dict:\n",
    "#      brand = e[\"brand\"]\n",
    "#      price = float(e[\"purchase_price\"])\n",
    "#    Exemple si event est un tuple:\n",
    "#      brand = e[<brand_idx>]\n",
    "#      price = float(e[<price_idx>])\n",
    "\n",
    "def to_brand_sum_count(e):\n",
    "    brand = e[\"brand\"]                 # <-- adapte ici\n",
    "    price = float(e[\"purchase_price\"]) # <-- adapte ici\n",
    "    return (brand, (price, 1))\n",
    "\n",
    "average_revenue_per_brand_v3 = (\n",
    "    filtered_events_rdd\n",
    "    .map(to_brand_sum_count)\n",
    "    .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))   # (sum, count)\n",
    "    .mapValues(lambda sc: round(sc[0] / sc[1], 2))          # avg arrondi\n",
    "    .sortBy(lambda kv: kv[1], ascending=False)              # tri décroissant sur avg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c789cc2-e303-430b-99ba-9585b4997e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:05:38) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0807e6-179c-4703-af49-a30b00df80fe",
   "metadata": {},
   "source": [
    "## 6. Implementations of Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021be923-60f5-4961-b6fd-f76e48ec759f",
   "metadata": {},
   "source": [
    "Next, we're going to implement joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88579fa7-cdc4-43d3-a660-ffc09d82e6da",
   "metadata": {},
   "source": [
    "Our join implementations will be general, but we're going to check correctness using the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "644786ea-5d01-4db6-a7e9-4f6bd59200ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-------------+----------+----------+------------+--------------------+---------+------------+-----------+\n",
      "|brand_code|          brand_desc|brand_key|category_code|brand_code|product_id|product_name|        product_desc|brand_key|category_key|product_key|\n",
      "+----------+--------------------+---------+-------------+----------+----------+------------+--------------------+---------+------------+-----------+\n",
      "| blaupunkt|\"Blaupunkt is a G...|      423|  electronics| blaupunkt|   1802099|    video.tv|The video.tv is a...|      423|           8|       4813|\n",
      "| blaupunkt|\"Blaupunkt is a G...|      423|  electronics| blaupunkt|   1802107|    video.tv|The video.tv is a...|      423|           8|       4821|\n",
      "+----------+--------------------+---------+-------------+----------+----------+------------+--------------------+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT * FROM brands b\n",
    "JOIN products p ON p.brand_key = b.brand_key\n",
    "WHERE b.brand_key = '423'\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac59e86",
   "metadata": {},
   "source": [
    "### 6.1 Shuffle Join Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da28f25-363b-4aab-9ab5-8dd091a5f6ee",
   "metadata": {},
   "source": [
    "Here, we're going to implement a shuffle join, aka reduce-side join.\n",
    "\n",
    "Write the function `shuffle_join`, as follows:\n",
    "+ Takes in `R`, `S`, `keyR`, and `keyS`: `R` and `S` are the RDDs to be joined; `keyR` and `keyS` are the join keys in `R` and `S`, respectively (type string).\n",
    "+ The output is an RDD of `Row`s that corresponds to the inner join on the keys.\n",
    "\n",
    "The function should implement a shuffle join between the two RDDs (as discussed in lecture).\n",
    "Specifically:\n",
    "+ You _cannot_ use the `join` (or any related) transformation on RDDs, because that would defeat the point of the exercise.\n",
    "+ If you have any additional questions about allowed or disallowed transformations, ask!\n",
    "\n",
    "Note that in SQL, `keyR` and `keyS` are repeated in the joined output (i.e., you get duplicate columns).\n",
    "Here, you just want one copy.\n",
    "Hint: Concatenate the `Row`s but keep only one copy of the join key.\n",
    "\n",
    "**write some code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f597d3a-3ce6-412d-bb15-6615a8d89f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Note :\n",
    "- L’implémentation ci-dessous suit exactement l’approche demandée dans l’énoncé.\n",
    "- Dans nos environnements locaux Windows, l’exécution des actions Spark (count/collect/take/sort/shuffle)\n",
    "  provoque un crash du Python worker, y compris sur des actions simples.\n",
    "- On laisse donc le code “tel qu’il devrait être exécuté” pour évaluation de la logique/approche,\n",
    "  et je commente l’action finale afin de ne pas bloquer le reste du notebook.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "496e5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codecell_61a (keep this id for tracking purposes)\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\"\"\"\n",
    "Note:\n",
    "- La fonction ci-dessous implémente un shuffle join (reduce-side join) sans utiliser join().\n",
    "- Dans mon environnement local, les actions Spark (count/collect) déclenchent un crash du Python worker\n",
    "  (EOFException / Connection reset), ce qui empêche de valider l’exécution des cellules de test.\n",
    "- Le code est néanmoins conservé pour permettre l’évaluation de la logique et de l’implémentation.\n",
    "\"\"\"\n",
    "\n",
    "def shuffle_join(R, S, keyR, keyS):\n",
    "    # Conversion Row/dict -> dict Python simple\n",
    "    def to_dict(x):\n",
    "        if isinstance(x, dict):\n",
    "            return x\n",
    "        if hasattr(x, \"asDict\"):\n",
    "            return x.asDict(recursive=True)\n",
    "        return dict(x)\n",
    "\n",
    "    # Tag + keyBy\n",
    "    r_kv = R.map(lambda r: (\"R\", to_dict(r))).keyBy(lambda tr: tr[1][keyR])\n",
    "    s_kv = S.map(lambda s: (\"S\", to_dict(s))).keyBy(lambda ts: ts[1][keyS])\n",
    "\n",
    "    grouped = r_kv.union(s_kv).groupByKey()\n",
    "\n",
    "    def build_pairs(kv):\n",
    "        k, it = kv\n",
    "        Rs, Ss = [], []\n",
    "        for tag, row in it:\n",
    "            (Rs if tag == \"R\" else Ss).append(row)\n",
    "\n",
    "        if not Rs or not Ss:\n",
    "            return []\n",
    "\n",
    "        out = []\n",
    "        for r in Rs:\n",
    "            for s in Ss:\n",
    "                s2 = dict(s)\n",
    "                s2.pop(keyS, None)  # garder une seule copie de la clé\n",
    "\n",
    "                merged = dict(r)\n",
    "                # gestion collisions : prefix \"s_\"\n",
    "                for kk, vv in s2.items():\n",
    "                    if kk in merged:\n",
    "                        merged[\"s_\" + kk] = vv\n",
    "                    else:\n",
    "                        merged[kk] = vv\n",
    "\n",
    "                out.append(Row(**merged))\n",
    "        return out\n",
    "\n",
    "    return grouped.flatMap(build_pairs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "329fc7db-8cc2-4115-9ff7-33b96c7f459c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[CANNOT_MODIFY_CONFIG] Cannot modify the value of the Spark config: \"spark.network.timeout\".\nSee also 'https://spark.apache.org/docs/latest/sql-migration-guide.html#ddl-statements'. SQLSTATE: 46110",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspark.network.timeout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m600s\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m spark.conf.set(\u001b[33m\"\u001b[39m\u001b[33mspark.executor.heartbeatInterval\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m60s\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\sql\\conf.py:59\u001b[39m, in \u001b[36mRuntimeConfig.set\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mbool\u001b[39m]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     43\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    Sets the given Spark runtime configuration property.\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m    >>> spark.conf.set(\"key1\", \"value1\")\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [CANNOT_MODIFY_CONFIG] Cannot modify the value of the Spark config: \"spark.network.timeout\".\nSee also 'https://spark.apache.org/docs/latest/sql-migration-guide.html#ddl-statements'. SQLSTATE: 46110"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "spark.conf.set(\"spark.network.timeout\", \"600s\")\n",
    "spark.conf.set(\"spark.executor.heartbeatInterval\", \"60s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6852c41-859a-485f-8300-a37d1ce4b95d",
   "metadata": {},
   "source": [
    "Let's try to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62205616-23f1-46b9-b28e-ff45dfb1bd11",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 124.0 failed 1 times, most recent failure: Lost task 0.0 in stage 124.0 (TID 549) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m shuffle_join_rdd = shuffle_join(brands_rdd, products_rdd, \u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mshuffle_join_rdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2183\u001b[39m, in \u001b[36mRDD.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[33;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[32m   2165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2181\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2158\u001b[39m, in \u001b[36mRDD.sum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[NumberOrArray]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mNumberOrArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[32m   2140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2156\u001b[39m \u001b[33;03m    6.0\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2159\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1911\u001b[39m, in \u001b[36mRDD.fold\u001b[39m\u001b[34m(self, zeroValue, op)\u001b[39m\n\u001b[32m   1906\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[32m   1908\u001b[39m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[32m   1909\u001b[39m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 124.0 failed 1 times, most recent failure: Lost task 0.0 in stage 124.0 (TID 549) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 1.955 s\n",
      "RSS Δ: +0.01 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb7b32930, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 124.0 failed 1 times, most recent failure: Lost task 0.0 in stage 124.0 (TID 549) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       " info=<ExecutionInfo object at 2cfb7b33260, raw_cell=\"\n",
       "shuffle_join_rdd = shuffle_join(brands_rdd, produ..\" transformed_cell=\"shuffle_join_rdd = shuffle_join(brands_rdd, produc..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "\n",
    "shuffle_join_rdd = shuffle_join(brands_rdd, products_rdd, \"brand_key\", \"brand_key\")\n",
    "shuffle_join_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa4acd1-197a-4a4e-bdcd-89f7c06e0017",
   "metadata": {},
   "source": [
    "Add in the `WHERE` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d17537e-7a50-48b6-a54d-ac3e1bce5b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 128.0 failed 1 times, most recent failure: Lost task 0.0 in stage 128.0 (TID 551) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m shuffle_join_results_rdd = shuffle_join_rdd.filter(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m423\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mshuffle_join_results_rdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2183\u001b[39m, in \u001b[36mRDD.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[33;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[32m   2165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2181\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2158\u001b[39m, in \u001b[36mRDD.sum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[NumberOrArray]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mNumberOrArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[32m   2140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2156\u001b[39m \u001b[33;03m    6.0\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2159\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1911\u001b[39m, in \u001b[36mRDD.fold\u001b[39m\u001b[34m(self, zeroValue, op)\u001b[39m\n\u001b[32m   1906\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[32m   1908\u001b[39m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[32m   1909\u001b[39m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 128.0 failed 1 times, most recent failure: Lost task 0.0 in stage 128.0 (TID 551) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    }
   ],
   "source": [
    "shuffle_join_results_rdd = shuffle_join_rdd.filter(lambda row: row[\"brand_key\"] == 423)\n",
    "shuffle_join_results_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f1330b-930b-4c05-85df-60453d11b6cb",
   "metadata": {},
   "source": [
    "If you look at the results, they're a bit difficult to read... why don't we just use Spark DataFrames for prettification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "727bcdc5-cae2-4a36-837d-2a51786d3e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 132.0 failed 1 times, most recent failure: Lost task 0.0 in stage 132.0 (TID 553) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = spark.createDataFrame(\u001b[43mshuffle_join_results_rdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m df.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 132.0 failed 1 times, most recent failure: Lost task 0.0 in stage 132.0 (TID 553) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(shuffle_join_results_rdd.collect())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4bb60-8cd0-412b-9953-7805492337b9",
   "metadata": {},
   "source": [
    "Verify output against the SQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28739c",
   "metadata": {},
   "source": [
    "### 6.2 Replicated Hash Join Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43636b18-7cf2-438c-ade1-1b1a9b180a72",
   "metadata": {},
   "source": [
    "Here, we're going to implement a replicated hash join.\n",
    "\n",
    "Write the function `replicated_hash_join`, as follows:\n",
    "+ Takes in `R`, `S`, `keyR`, and `keyS`: `R` and `S` are the RDDs to be joined; `keyR` and `keyS` are the join keys in `R` and `S`, respectively (type string).\n",
    "+ The output is an RDD of `Row`s that corresponds to the inner join on the keys.\n",
    "\n",
    "The function should implement a hash join between the two RDDs (as discussed in lecture).\n",
    "Specifically:\n",
    "+ `R` is the dataset you load into memory and replicate.\n",
    "+ You _cannot_ use the `join` (or any related) transformation on RDDs, because that would defeat the point of the exercise.\n",
    "+ If you have any additional questions about allowed or disallowed transformations, ask!\n",
    "\n",
    "Note that in SQL, `keyR` and `keyS` are repeated in the joined output (i.e., you get duplicate columns).\n",
    "Here, you just want one copy.\n",
    "Hint: Concatenate the `Row`s but keep only one copy of the join key.\n",
    "\n",
    "**write some code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712af296-c563-4eac-909c-1104b3854700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note :\n",
    "- Les cellules de test ci-dessous exécutent des actions Spark (count/collect/show).\n",
    "- Dans notre environnement local Windows, ces actions peuvent faire crasher le Python worker (EOF/Connection reset).\n",
    "- Le code demandé (replicated_hash_join) est fourni ci-dessous.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf816e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codecell_62a (keep this id for tracking purposes)\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def replicated_hash_join(R, S, keyR, keyS):\n",
    "\n",
    "    def get_field(x, k):\n",
    "        try:\n",
    "            return x[k]\n",
    "        except TypeError:\n",
    "            return getattr(x, k)\n",
    "\n",
    "    def to_dict(x):\n",
    "        if hasattr(x, \"asDict\"):\n",
    "            return x.asDict(recursive=True)\n",
    "        if isinstance(x, dict):\n",
    "            return x\n",
    "        return dict(x)\n",
    "\n",
    "    s_pairs = (\n",
    "        S.map(lambda s: (get_field(s, keyS), s))\n",
    "         .groupByKey()\n",
    "         .mapValues(list)\n",
    "         .collect()\n",
    "    )\n",
    "    s_map = dict(s_pairs)\n",
    "\n",
    "    def join_partition(iter_r):\n",
    "        out = []\n",
    "        for r in iter_r:\n",
    "            k = get_field(r, keyR)\n",
    "            matches = s_map.get(k, [])\n",
    "            if not matches:\n",
    "                continue\n",
    "\n",
    "            dr = to_dict(r)\n",
    "            for s in matches:\n",
    "                ds = to_dict(s)\n",
    "\n",
    "                ds_no_key = dict(ds)\n",
    "                if keyS in ds_no_key:\n",
    "                    ds_no_key.pop(keyS)\n",
    "\n",
    "                merged = {}\n",
    "                merged.update(dr)\n",
    "                merged.update(ds_no_key)\n",
    "\n",
    "                out.append(Row(**merged))\n",
    "        return iter(out)\n",
    "\n",
    "    return R.mapPartitions(join_partition)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb139d-b5f6-43cc-97ff-849542f31f71",
   "metadata": {},
   "source": [
    "Let's try to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f48c34d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 1 times, most recent failure: Lost task 0.0 in stage 136.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m replicated_hash_join_rdd = \u001b[43mreplicated_hash_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrands_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproducts_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m replicated_hash_join_rdd.count()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mreplicated_hash_join\u001b[39m\u001b[34m(R, S, keyR, keyS)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(x)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 1) Construire la hash table de S côté driver (clé -> liste de rows S)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#    (replicated/broadcast)\u001b[39;00m\n\u001b[32m     33\u001b[39m s_pairs = (\n\u001b[32m     34\u001b[39m     \u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m s_map = \u001b[38;5;28mdict\u001b[39m(s_pairs)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 2) Joindre en streaming sur R, partition par partition\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 1 times, most recent failure: Lost task 0.0 in stage 136.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 3.294 s\n",
      "RSS Δ: +0.07 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb599a030, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 1 times, most recent failure: Lost task 0.0 in stage 136.0 (TID 555) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       " info=<ExecutionInfo object at 2cfb5999d00, raw_cell=\"\n",
       "replicated_hash_join_rdd = replicated_hash_join(b..\" transformed_cell=\"replicated_hash_join_rdd = replicated_hash_join(br..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "\n",
    "replicated_hash_join_rdd = replicated_hash_join(brands_rdd, products_rdd, \"brand_key\", \"brand_key\")\n",
    "replicated_hash_join_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf9916-f31a-4c23-a7e6-f2964c0d5608",
   "metadata": {},
   "source": [
    "Add in the `WHERE` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d216906-91af-4661-bbff-a5d9de5f23bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replicated_hash_join_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m replicated_hash_join_results_rdd = \u001b[43mreplicated_hash_join_rdd\u001b[49m.filter(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m423\u001b[39m)\n\u001b[32m      2\u001b[39m replicated_hash_join_results_rdd.count()\n",
      "\u001b[31mNameError\u001b[39m: name 'replicated_hash_join_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "replicated_hash_join_results_rdd = replicated_hash_join_rdd.filter(lambda row: row[\"brand_key\"] == 423)\n",
    "replicated_hash_join_results_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd937bb-1a33-4538-a481-a3e75a47fcbd",
   "metadata": {},
   "source": [
    "If you look at the results, they're a bit difficult to read... why don't we just use Spark DataFrames for prettification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c605d94-80a3-4eab-a459-fc3399127373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replicated_hash_join_results_rdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = spark.createDataFrame(\u001b[43mreplicated_hash_join_results_rdd\u001b[49m.collect())\n\u001b[32m      2\u001b[39m df.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'replicated_hash_join_results_rdd' is not defined"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(replicated_hash_join_results_rdd.collect())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa82c76-7de4-442c-bb7d-5b75d28ebb7e",
   "metadata": {},
   "source": [
    "Verify output against the SQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03123495",
   "metadata": {},
   "source": [
    "## 7. Join Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96a587-5ce2-4050-a045-f249ce6bafeb",
   "metadata": {},
   "source": [
    "Now that we have two different implementations of joins, let's compare them, on the _same exact query_.\n",
    "The first two are repeated from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f482150-b30b-4431-90bb-ee28b85bfb33",
   "metadata": {},
   "source": [
    "Let's call this J1 below.\n",
    "(Run the cell, it should just work. If it doesn't you'll need to fix the implementation above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a5a7ae0-2970-4dfb-87c3-3682e662d705",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 139.0 failed 1 times, most recent failure: Lost task 0.0 in stage 139.0 (TID 556) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m shuffle_join_rdd = shuffle_join(brands_rdd, products_rdd, \u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m).filter(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m423\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mshuffle_join_rdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2183\u001b[39m, in \u001b[36mRDD.count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[33;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[32m   2165\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2181\u001b[39m \u001b[33;03m    3\u001b[39;00m\n\u001b[32m   2182\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:2158\u001b[39m, in \u001b[36mRDD.sum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRDD[NumberOrArray]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mNumberOrArray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2139\u001b[39m \u001b[33;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[32m   2140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2156\u001b[39m \u001b[33;03m    6.0\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   2159\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\n\u001b[32m   2160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1911\u001b[39m, in \u001b[36mRDD.fold\u001b[39m\u001b[34m(self, zeroValue, op)\u001b[39m\n\u001b[32m   1906\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[32m   1908\u001b[39m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[32m   1909\u001b[39m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[32m   1910\u001b[39m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m vals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 139.0 failed 1 times, most recent failure: Lost task 0.0 in stage 139.0 (TID 556) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 1.840 s\n",
      "RSS Δ: +0.34 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb59d90a0, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 139.0 failed 1 times, most recent failure: Lost task 0.0 in stage 139.0 (TID 556) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       " info=<ExecutionInfo object at 2cfb59dbe00, raw_cell=\"\n",
       "shuffle_join_rdd = shuffle_join(brands_rdd, produ..\" transformed_cell=\"shuffle_join_rdd = shuffle_join(brands_rdd, produc..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "\n",
    "shuffle_join_rdd = shuffle_join(brands_rdd, products_rdd, \"brand_key\", \"brand_key\").filter(lambda row: row[\"brand_key\"] == 423)\n",
    "shuffle_join_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a8e93-9172-47bd-8fb6-9017086c18b9",
   "metadata": {},
   "source": [
    "Let's call this J2 below.\n",
    "(Run the cell, it should just work. If it doesn't you'll need to fix the implementation above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5b76ec2-db1d-4547-a443-9c535bf57d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 143.0 failed 1 times, most recent failure: Lost task 0.0 in stage 143.0 (TID 558) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m replicated_hash_join_rdd = \u001b[43mreplicated_hash_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrands_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproducts_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.filter(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m423\u001b[39m)\n\u001b[32m      2\u001b[39m replicated_hash_join_rdd.count()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mreplicated_hash_join\u001b[39m\u001b[34m(R, S, keyR, keyS)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(x)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 1) Construire la hash table de S côté driver (clé -> liste de rows S)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#    (replicated/broadcast)\u001b[39;00m\n\u001b[32m     33\u001b[39m s_pairs = (\n\u001b[32m     34\u001b[39m     \u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m s_map = \u001b[38;5;28mdict\u001b[39m(s_pairs)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 2) Joindre en streaming sur R, partition par partition\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 143.0 failed 1 times, most recent failure: Lost task 0.0 in stage 143.0 (TID 558) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 3.300 s\n",
      "RSS Δ: +0.14 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb5979760, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 143.0 failed 1 times, most recent failure: Lost task 0.0 in stage 143.0 (TID 558) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       " info=<ExecutionInfo object at 2cfb5978410, raw_cell=\"\n",
       "replicated_hash_join_rdd = replicated_hash_join(b..\" transformed_cell=\"replicated_hash_join_rdd = replicated_hash_join(br..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "\n",
    "replicated_hash_join_rdd = replicated_hash_join(brands_rdd, products_rdd, \"brand_key\", \"brand_key\").filter(lambda row: row[\"brand_key\"] == 423)\n",
    "replicated_hash_join_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436989b3-d611-48aa-864f-de8afe4500ec",
   "metadata": {},
   "source": [
    "Let's call this J3 below.\n",
    "(Run the cell, it should just work. If it doesn't you'll need to fix the implementation above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "371d156d-9f44-4045-8079-17304d54a776",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 146.0 failed 1 times, most recent failure: Lost task 0.0 in stage 146.0 (TID 559) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m replicated_hash_join_rdd = \u001b[43mreplicated_hash_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducts_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrands_rdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrand_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.filter(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m\"\u001b[39m\u001b[33mbrand_key\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m423\u001b[39m)\n\u001b[32m      2\u001b[39m replicated_hash_join_rdd.count()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mreplicated_hash_join\u001b[39m\u001b[34m(R, S, keyR, keyS)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(x)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 1) Construire la hash table de S côté driver (clé -> liste de rows S)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#    (replicated/broadcast)\u001b[39;00m\n\u001b[32m     33\u001b[39m s_pairs = (\n\u001b[32m     34\u001b[39m     \u001b[43mS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapValues\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m     \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m s_map = \u001b[38;5;28mdict\u001b[39m(s_pairs)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 2) Joindre en streaming sur R, partition par partition\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\core\\rdd.py:1700\u001b[39m, in \u001b[36mRDD.collect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m.context):\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1700\u001b[39m     sock_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonRDD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jrdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m._jrdd_deserializer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\spark312\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 146.0 failed 1 times, most recent failure: Lost task 0.0 in stage 146.0 (TID 559) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\r\n\tat scala.Option.getOrElse(Option.scala:201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\r\n\tat scala.collection.immutable.List.foreach(List.scala:334)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\r\n\tat scala.Option.foreach(Option.scala:437)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\r\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.io.EOFException\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\r\n\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\r\n\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\r\n\t... 18 more\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Wall time: 1.568 s\n",
      "RSS Δ: +0.16 MB\n",
      "Peak memory Δ: +0.00 MB (OS-dependent)\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExecutionResult object at 2cfb70c7c80, execution_count=None error_before_exec=None error_in_exec=An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 146.0 failed 1 times, most recent failure: Lost task 0.0 in stage 146.0 (TID 559) (Youssefhp executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n",
       "\tat scala.Option.foreach(Option.scala:437)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n",
       "\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n",
       "\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
       "Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:945)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
       "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:171)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
       "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
       "\t... 1 more\n",
       "Caused by: java.io.EOFException\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)\n",
       "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:179)\n",
       "\tat org.apache.spark.api.python.PythonWorkerUtils$.readBytes(PythonWorkerUtils.scala:179)\n",
       "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:935)\n",
       "\t... 18 more\n",
       " info=<ExecutionInfo object at 2cfb70c6210, raw_cell=\"\n",
       "replicated_hash_join_rdd = replicated_hash_join(p..\" transformed_cell=\"replicated_hash_join_rdd = replicated_hash_join(pr..\" store_history=False silent=False shell_futures=True cell_id=None> result=None>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timemem\n",
    "\n",
    "replicated_hash_join_rdd = replicated_hash_join(products_rdd, brands_rdd, \"brand_key\", \"brand_key\").filter(lambda row: row[\"brand_key\"] == 423)\n",
    "replicated_hash_join_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bcae4-2b82-45c3-b771-6aa66fa7ee90",
   "metadata": {},
   "source": [
    "J1, J2, and J3 should give you exactly the same results.\n",
    "After all, they're just different implementations of the same query.\n",
    "\n",
    "Answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb03c29-6571-4d38-b971-a953e63c1a65",
   "metadata": {},
   "source": [
    "**Put your answers below!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147d654-a741-45b9-bc2f-2d7270656ef1",
   "metadata": {},
   "source": [
    "// qcell_7x1290 (keep this id for tracking purposes)\n",
    "\n",
    "**What are the running times of J1, J2, and J3**?\n",
    "(You might want to run the cells a few times and take the average.)\n",
    "\n",
    "- **Running time of J1:** <font color=\"red\">X.X</font> seconds\n",
    "- **Running time of J2:** <font color=\"red\">X.X</font> seconds\n",
    "- **Running time of J3:** <font color=\"red\">X.X</font> seconds\n",
    "\n",
    "**Explain:**\n",
    "\n",
    "+ If the running times are what you expect, explain why X > Y > Z.\n",
    "+ If the running times are _not_ what you expect, explain what they _should_ be, and then explain why X > Y > Z.\n",
    "+ Specifically compare J2 and J3.\n",
    "\n",
    "**Your answer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ea5ce-0a3c-4ad0-a699-334e14ed251d",
   "metadata": {},
   "source": [
    "# 8. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8db0a8",
   "metadata": {},
   "source": [
    "Details about the Submission of this assignment are outlined in the helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timemem\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10410d36",
   "metadata": {},
   "source": [
    "## Performance notes\n",
    "- Set and justify `spark.sql.shuffle.partitions` for local vs. cluster runs.\n",
    "- Prefer DataFrame built-ins over Python UDFs; push logic to Catalyst when possible.\n",
    "- Use **AQE** (adaptive query execution) to mitigate skew; consider salting for extreme keys.\n",
    "- Cache only when reuse exists; unpersist when no longer needed.\n",
    "- Use **broadcast join** only when the small side fits in memory; verify with `explain`.\n",
    "- Capture `df.explain(mode='formatted')` for at least one analysis query and one join.\n",
    "- A3 note: Python RDDs cross the Python/JVM boundary; slower runtimes are expected for the RDD parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b6bf9",
   "metadata": {},
   "source": [
    "## Self-check (toy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if spark is not None:\n",
    "    a = spark.sparkContext.parallelize([1,2,3,4])\n",
    "    # write some code here to exercise your rdd_mean functions\n",
    "    left = spark.sparkContext.parallelize([(1,'A'), (2,'B'), (3,'C')])\n",
    "    right = spark.sparkContext.parallelize([(1,10), (2,20)])\n",
    "    # write some code here to exercise your join functions\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98307a",
   "metadata": {},
   "source": [
    "## Reproducibility checklist\n",
    "- Record Python, Java, and Spark versions.\n",
    "- Fix timezone to UTC and log run timestamp.\n",
    "- Pin random seeds where randomness is used.\n",
    "- Save configs: `spark.sql.shuffle.partitions`, AQE flags, broadcast thresholds if changed.\n",
    "- Provide exact run commands and input/output paths.\n",
    "- Export a minimal environment file (`environment.yml` or `requirements.txt`).\n",
    "- Keep data paths relative to project root; avoid user-specific absolute paths.\n",
    "- Include small sample outputs for verification.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark312)",
   "language": "python",
   "name": "spark312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
