== Physical Plan ==
AdaptiveSparkPlan (15)
+- Sort (14)
   +- Exchange (13)
      +- HashAggregate (12)
         +- Exchange (11)
            +- HashAggregate (10)
               +- Project (9)
                  +- BroadcastHashJoin LeftOuter BuildRight (8)
                     :- InMemoryTableScan (1)
                     :     +- InMemoryRelation (2)
                     :           +- * ColumnarToRow (4)
                     :              +- Scan parquet  (3)
                     +- BroadcastExchange (7)
                        +- Filter (6)
                           +- Scan csv  (5)


(1) InMemoryTableScan
Output [2]: [curr_title#653, n#655]
Arguments: [curr_title#653, n#655]

(2) InMemoryRelation
Arguments: [prev_title#652, curr_title#653, type#654, n#655, ts#656, year#657, month#658], StorageLevel(disk, memory, deserialized, 1 replicas)

(3) Scan parquet 
Output [7]: [prev_title#652, curr_title#653, type#654, n#655, ts#656, year#657, month#658]
Batched: true
Location: InMemoryFileIndex [file:/D:/DataEngineering/lab3/labpractice/outputs/lab3/columnar/clicks_parquet]
ReadSchema: struct<prev_title:string,curr_title:string,type:string,n:int,ts:timestamp>

(4) ColumnarToRow [codegen id : 1]
Input [7]: [prev_title#652, curr_title#653, type#654, n#655, ts#656, year#657, month#658]

(5) Scan csv 
Output [2]: [curr_title#997, curr_category#998]
Batched: false
Location: InMemoryFileIndex [file:/D:/DataEngineering/lab3/labpractice/data/lab3_dim_curr_category.csv]
PushedFilters: [IsNotNull(curr_title)]
ReadSchema: struct<curr_title:string,curr_category:string>

(6) Filter
Input [2]: [curr_title#997, curr_category#998]
Condition : isnotnull(curr_title#997)

(7) BroadcastExchange
Input [2]: [curr_title#997, curr_category#998]
Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=266]

(8) BroadcastHashJoin
Left keys [1]: [curr_title#653]
Right keys [1]: [curr_title#997]
Join type: LeftOuter
Join condition: None

(9) Project
Output [2]: [n#655, curr_category#998]
Input [4]: [curr_title#653, n#655, curr_title#997, curr_category#998]

(10) HashAggregate
Input [2]: [n#655, curr_category#998]
Keys [1]: [curr_category#998]
Functions [1]: [partial_sum(n#655)]
Aggregate Attributes [1]: [sum#1232L]
Results [2]: [curr_category#998, sum#1233L]

(11) Exchange
Input [2]: [curr_category#998, sum#1233L]
Arguments: hashpartitioning(curr_category#998, 200), ENSURE_REQUIREMENTS, [plan_id=271]

(12) HashAggregate
Input [2]: [curr_category#998, sum#1233L]
Keys [1]: [curr_category#998]
Functions [1]: [sum(n#655)]
Aggregate Attributes [1]: [sum(n#655)#1126L]
Results [2]: [curr_category#998, sum(n#655)#1126L AS total_n#1117L]

(13) Exchange
Input [2]: [curr_category#998, total_n#1117L]
Arguments: rangepartitioning(total_n#1117L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=274]

(14) Sort
Input [2]: [curr_category#998, total_n#1117L]
Arguments: [total_n#1117L DESC NULLS LAST], true, 0

(15) AdaptiveSparkPlan
Output [2]: [curr_category#998, total_n#1117L]
Arguments: isFinalPlan=false


